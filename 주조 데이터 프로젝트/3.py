import joblib
import pandas as pd
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.metrics import mean_squared_error, r2_score

# 1. ëª¨ë¸ì´ í¬í•¨ëœ ë”•ì…”ë„ˆë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°
try:
    loaded_object = joblib.load('final_model.pkl')
    
    # ğŸ‘‡ğŸ‘‡ğŸ‘‡ ì´ ë¶€ë¶„ì´ í•µì‹¬! ë”•ì…”ë„ˆë¦¬ì—ì„œ ì‹¤ì œ ëª¨ë¸ì„ ì¶”ì¶œí•©ë‹ˆë‹¤. ğŸ‘‡ğŸ‘‡ğŸ‘‡
    if isinstance(loaded_object, dict):
        model = loaded_object.get("model")
        print("âœ… ë”•ì…”ë„ˆë¦¬ì—ì„œ ëª¨ë¸ì„ ì„±ê³µì ìœ¼ë¡œ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.")
    else:
        model = loaded_object # ë§Œì•½ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹ˆë©´, ê·¸ ìì²´ê°€ ëª¨ë¸
        print("âœ… ëª¨ë¸ì„ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")

    if not hasattr(model, 'predict'):
        print("ğŸš¨ ì˜¤ë¥˜: ì¶”ì¶œëœ ê°ì²´ì— predict ê¸°ëŠ¥ì´ ì—†ìŠµë‹ˆë‹¤. .pkl íŒŒì¼ì˜ êµ¬ì¡°ë¥¼ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")
        exit()

except FileNotFoundError:
    print("ğŸš¨ 'final_model.pkl' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    exit()
except Exception as e:
    print(f"ğŸš¨ ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    exit()

# 2. í…ŒìŠ¤íŠ¸ ë°ì´í„° ë° ì‹¤ì œ ì •ë‹µ ë¶ˆëŸ¬ì˜¤ê¸°
try:
    X_test = pd.read_csv('./test.csv')
    y_true = pd.read_csv('./.csv').squeeze()
    print("âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„°ì™€ ì •ë‹µ ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
except FileNotFoundError as e:
    print(f"ğŸš¨ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e.filename}. íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    exit()

# 3. ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡ ìˆ˜í–‰
predictions = model.predict(X_test)
print("\nâœ… ì˜ˆì¸¡ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.")

# ê²°ê³¼ í™•ì¸
results_df = pd.DataFrame({'Actual': y_true, 'Predicted': predictions})
print("\n[ì‹¤ì œ ê°’ê³¼ ì˜ˆì¸¡ ê°’ ë¹„êµ (ìƒìœ„ 5ê°œ)]")
print(results_df.head())

# 4. ì„±ëŠ¥ í‰ê°€
print("\n--- ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ---")

if y_true.dtype == 'object' or y_true.nunique() < 20:
    print("ğŸ“ˆ **ë¶„ë¥˜ ëª¨ë¸ ì„±ëŠ¥**")
    accuracy = accuracy_score(y_true, predictions)
    precision = precision_score(y_true, predictions, average='macro')
    recall = recall_score(y_true, predictions, average='macro')
    f1 = f1_score(y_true, predictions, average='macro')

    print(f"  - ì •í™•ë„ (Accuracy): {accuracy:.4f}")
    print(f"  - ì •ë°€ë„ (Precision): {precision:.4f}")
    print(f"  - ì¬í˜„ìœ¨ (Recall): {recall:.4f}")
    print(f"  - F1 ìŠ¤ì½”ì–´ (F1 Score): {f1:.4f}")
else:
    print("ğŸ“ˆ **íšŒê·€ ëª¨ë¸ ì„±ëŠ¥**")
    mse = mean_squared_error(y_true, predictions)
    rmse = mse ** 0.5
    r2 = r2_score(y_true, predictions)

    print(f"  - í‰ê·  ì œê³± ì˜¤ì°¨ (MSE): {mse:.4f}")
    print(f"  - í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨ (RMSE): {rmse:.4f}")
    print(f"  - R-ì œê³± (RÂ²): {r2:.4f}")