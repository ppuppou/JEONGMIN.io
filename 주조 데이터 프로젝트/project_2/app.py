import pandas as pd
import numpy as np
import joblib
import shiny
from shiny import App, ui, render, reactive
from pathlib import Path
import datetime
from datetime import datetime, timedelta
import os
import asyncio
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('Agg')
import warnings
import re
import google.generativeai as genai
from scipy.stats import ks_2samp
import seaborn as sns
import pickle

warnings.filterwarnings("ignore", message="X does not have valid feature names", category=UserWarning)
warnings.filterwarnings("ignore", category=FutureWarning)
warnings.filterwarnings("ignore", category=UserWarning)

# --- sharedì—ì„œ ëª¨ë¸ê³¼ ë™ì¼ ì „ì²˜ë¦¬/í”¼ì²˜ ìˆœì„œ/ì˜ˆì¸¡í•¨ìˆ˜ ê°€ì ¸ì˜¤ê¸° ---
from shared import ANOM_PREPROCESSOR, ANOM_FEATURE_ORDER, anomaly_transform, get_preproc_feature_names_out
from shared import (
    streaming_df, RealTimeStreamer, defect_model, feature_cols,
    train_df, test_label_df, test_df, predict_anomaly, defect_threshold, model_dict,
    ANOMALY_PROBA_THRESHOLD
)

# ARIMA í†µê³„ ë¡œë“œ
arima_stats = {}
arima_pkl_path = "./data/arima_stats.pkl"
if os.path.exists(arima_pkl_path):
    try:
        with open(arima_pkl_path, 'rb') as f:
            arima_stats = pickle.load(f)
        print(f"âœ… ARIMA í†µê³„ ë¡œë“œ ì™„ë£Œ: {len(arima_stats)}ê°œ ë³€ìˆ˜")
    except Exception as e:
        print(f"âš ï¸ ARIMA í†µê³„ ë¡œë“œ ì‹¤íŒ¨: {e}")
else:
    print(f"âš ï¸ {arima_pkl_path} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# ë“œë¦¬í”„íŠ¸ ì œì™¸ ì»¬ëŸ¼
excluded_drift_cols = [
    'count', 'hour', 'EMS_operation_time', 'tryshot_signal',
    'mold_code', 'heating_furnace'
]
drift_feature_choices = [col for col in feature_cols if col not in excluded_drift_cols]

# í•œê¸€ í°íŠ¸ ì„¤ì •
import platform
from matplotlib import font_manager, rc
from sklearn.neighbors import NearestNeighbors
from sklearn.isotonic import IsotonicRegression
from sklearn.impute import SimpleImputer
from collections import defaultdict
import matplotlib.pyplot as plt
import plotly.io as pio

# í°íŠ¸ íŒŒì¼ ê²½ë¡œ
APP_DIR = os.path.dirname(os.path.abspath(__file__))
font_path = os.path.join(APP_DIR, "www", "fonts", "NanumGothic-Regular.ttf")

# í°íŠ¸ ì ìš©
if os.path.exists(font_path):
    font_manager.fontManager.addfont(font_path)
    plt.rcParams["font.family"] = "NanumGothic"  # Matplotlib
    print(f"âœ… í•œê¸€ í°íŠ¸ ì ìš©ë¨: {font_path}")
else:
    plt.rcParams["font.family"] = "sans-serif"
    print(f"âš ï¸ í•œê¸€ í°íŠ¸ íŒŒì¼ ì—†ìŒ â†’ {font_path}")

# ë§ˆì´ë„ˆìŠ¤ ë¶€í˜¸ ê¹¨ì§ ë°©ì§€
plt.rcParams["axes.unicode_minus"] = False

# Plotly ê¸°ë³¸ í°íŠ¸ ì„¤ì •
pio.templates["nanum"] = pio.templates["plotly_white"].update(
    layout_font=dict(family="NanumGothic")
)
pio.templates.default = "nanum"

# plt.rcParams['axes.unicode_minus'] = False
# if platform.system() == 'Darwin':
#     rc('font', family='AppleGothic')
# elif platform.system() == 'Windows':
#     path = "c:/Windows/Fonts/malgun.ttf"
#     font_name = font_manager.FontProperties(fname=path).get_name()
#     rc('font', family=font_name)
# else:
#     try:
#         if platform.system() == 'Linux':
#             font_paths = ['/usr/share/fonts/truetype/nanum/NanumGothic.ttf', 
#                           '/usr/share/fonts/nanum/NanumGothic.ttf',
#                           '/usr/local/share/fonts/NanumGothic.ttf']
#             font_path = None
#             for path in font_paths:
#                 if os.path.exists(path):
#                     font_path = path
#                     break
#             if font_path:
#                 font_name = font_manager.FontProperties(fname=font_path).get_name()
#                 rc('font', family=font_name)
#             else:
#                 rc('font', family='NanumBarunGothic')
#         else:
#             rc('font', family='NanumBarunGothic')
#     except Exception:
#         rc('font', family='NanumBarunGothic')

TARGET_COL = 'passorfail'
PREDICTION_THRESHOLD = defect_threshold
CHUNK_SIZE = 200
DRIFT_CHUNK_SIZE = 100
CAL_K = 80
_MAX_CAL_SAMPLES = 500
_RIDGE = 1e-6
startup_error = ""

# ê²€ì¦ ì„±ëŠ¥
validation_recall = 0.0
validation_precision = 0.0
recall_lcl = 0.0
precision_lcl = 0.0

# ==================== ì´ìƒì¹˜ ì„¤ëª… ì¤€ë¹„ ====================
INPUT_FEATURES = ANOM_FEATURE_ORDER if len(ANOM_FEATURE_ORDER) else feature_cols

try:
    PREPROC_FEATURES = list(get_preproc_feature_names_out())
except Exception:
    PREPROC_FEATURES = [f"feat_{i}" for i in range(anomaly_transform(train_df[INPUT_FEATURES]).shape[1])]

def _base_from_preproc_name(name: str) -> str:
    n = str(name).split("__")[-1]
    if "=" in n:
        return n.split("=")[0]
    cand = n.rsplit("_", 1)[0]
    return cand if cand in INPUT_FEATURES else n

_GROUP_IDX = defaultdict(list)
_PREPROC_BASES = []
for j, pname in enumerate(PREPROC_FEATURES):
    base = _base_from_preproc_name(pname)
    if base == pname and pname.startswith("feat_"):
        if j < len(INPUT_FEATURES):
            base = INPUT_FEATURES[j]
    _PREPROC_BASES.append(base)
    _GROUP_IDX[base].append(j)

# ìˆ«ìží˜• ê²°ì¸¡ ëŒ€ì¹˜ê°’ ì¶”ì¶œ
_NUM_IMPUTE_STATS = {}
try:
    if hasattr(ANOM_PREPROCESSOR, "transformers_"):
        for _, trans, cols in ANOM_PREPROCESSOR.transformers_:
            if hasattr(trans, "named_steps") and "imputer" in trans.named_steps:
                imp = trans.named_steps["imputer"]
                if isinstance(imp, SimpleImputer) and hasattr(imp, "statistics_"):
                    for c, v in zip(cols, imp.statistics_):
                        _NUM_IMPUTE_STATS[c] = v
            elif isinstance(trans, SimpleImputer) and hasattr(trans, "statistics_"):
                for c, v in zip(cols, trans.statistics_):
                    _NUM_IMPUTE_STATS[c] = v
except Exception:
    pass

def _imputed_raw(row: pd.Series, base: str):
    v = row.get(base, np.nan)
    if pd.isna(v) and base in _NUM_IMPUTE_STATS:
        return _NUM_IMPUTE_STATS[base]
    return v

_Z_ref = None
_nn_model = None
try:
    # 1ë‹¨ê³„ì—ì„œ ìƒì„±í•œ .pkl íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤.
    exp_path = os.path.join(APP_DIR, "data", "explanation_model.pkl")
    exp_bundle = joblib.load(exp_path)
    
    _Z_ref = exp_bundle.get("Z_ref")
    _nn_model = exp_bundle.get("nn_model")
    
    if _Z_ref is not None and _nn_model is not None:
        print(f"âœ… ì´ìƒì¹˜ ì„¤ëª… ëª¨ë¸(NN) ë¡œë“œ ì™„ë£Œ (Ref Shape: {_Z_ref.shape})")
    else:
        raise ValueError("ëª¨ë¸ì€ ë¡œë“œí–ˆìœ¼ë‚˜ 'Z_ref' ë˜ëŠ” 'nn_model' í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")

except FileNotFoundError:
    print(f"âš ï¸ 'explanation_model.pkl' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print("   -> ðŸ”´ ì¤‘ìš”: ë°°í¬ ì „, ë¡œì»¬ì—ì„œ 'create_explanation_model.py' ë¥¼ ì‹¤í–‰í•´ì•¼ í•©ë‹ˆë‹¤.")
except Exception as e:
    print(f"âš ï¸ ì´ìƒì¹˜ ì„¤ëª… ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
# ðŸ”´ [ìˆ˜ì • ì™„ë£Œ] ðŸ”´

def _xi_from_row(row: pd.Series) -> np.ndarray:
    X1 = pd.DataFrame([row]).reindex(columns=INPUT_FEATURES)
    Zi = anomaly_transform(X1)[0]
    return Zi

def _local_mahalanobis_parts(xi: np.ndarray):
    _, idx = _nn_model.kneighbors([xi], n_neighbors=min(CAL_K, len(_Z_ref)))
    neigh = _Z_ref[idx[0]]
    mu = neigh.mean(axis=0)
    Sigma = np.cov(neigh, rowvar=False)
    Sigma = Sigma + np.eye(Sigma.shape[0]) * _RIDGE
    invS = np.linalg.pinv(Sigma)
    diff = xi - mu
    parts = diff * (invS @ diff)
    D2 = float(diff @ invS @ diff)
    return parts, D2, mu

def _effective_anom_proba(ana_res: pd.DataFrame):
    aprob_raw = float(ana_res.get("anom_proba", [np.nan])[0]) if "anom_proba" in ana_res.columns else np.nan
    strength = float(ana_res.get("prob", [np.nan])[0]) if "prob" in ana_res.columns else np.nan
    if (not np.isfinite(aprob_raw)) or (aprob_raw <= 0):
        aprob_eff = 1.0 - (strength if np.isfinite(strength) else 0.0)
    else:
        aprob_eff = aprob_raw
    return aprob_eff, strength

# Isotonic ë³´ì •
_iso = None
_cal_bounds = None
_cal_d2, _cal_p = None, None # ì°¸ì¡°ìš© (ì´ì œ ì‚¬ìš© ì•ˆ í•¨)

try:
    # 1ë‹¨ê³„ì—ì„œ ìƒì„±í•œ .pkl íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤.
    cal_path = os.path.join(APP_DIR, "data", "calibration_model.pkl")
    cal_bundle = joblib.load(cal_path)
    
    _iso = cal_bundle.get("iso_model")
    _cal_bounds = cal_bundle.get("cal_bounds")
    
    if _iso is not None:
        print("âœ… Isotonic ë³´ì • ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    else:
        raise ValueError("ëª¨ë¸ì€ ë¡œë“œí–ˆìœ¼ë‚˜ 'iso_model' í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")

except FileNotFoundError:
    print(f"âš ï¸ 'calibration_model.pkl' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print("   -> ðŸ”´ ì¤‘ìš”: ë°°í¬ ì „, ë¡œì»¬ì—ì„œ 'create_calibration_model.py' ë¥¼ ì‹¤í–‰í•´ì•¼ í•©ë‹ˆë‹¤.")
except Exception as e:
    print(f"âš ï¸ Isotonic ë³´ì • ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
# ðŸ”´ [ìˆ˜ì • ì™„ë£Œ] ðŸ”´

# Isotonic ë³´ì • (ì´ í•¨ìˆ˜ë“¤ì€ _iso, _cal_boundsë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ 'ì •ì˜'ëŠ” ê·¸ëŒ€ë¡œ ë‘¡ë‹ˆë‹¤)

def _p_of_D2(D2: float) -> float:
    if _iso is None:
        return float("nan")
    if _cal_bounds is None:
        return float(_iso.predict([D2])[0])
    lo, hi = _cal_bounds
    x = min(max(float(D2), lo), hi)
    return float(_iso.predict([x])[0])

def _dp_dD2(D2: float) -> float:
    if _iso is None:
        return 0.0
    lo, hi = _cal_bounds if _cal_bounds is not None else (D2-1.0, D2+1.0)
    width = max(hi - lo, 1.0)
    eps = 1e-3 * width
    x = lo + eps if D2 <= lo else (hi - eps if D2 >= hi else float(D2))
    p_plus = float(_iso.predict([x + eps])[0])
    p_minus = float(_iso.predict([x - eps])[0])
    return (p_plus - p_minus) / (2.0 * eps)

def explain_hdbscan_local_influence_prob(row: pd.Series, topn: int = 5):
    try:
        xi = _xi_from_row(row)
        parts, D2, mu = _local_mahalanobis_parts(xi)
        slope = _dp_dD2(D2)
        deltas = slope * parts
        
        items = []
        for base, idxs in _GROUP_IDX.items():
            dp_sum = float(np.sum(deltas[idxs]))
            raw_val = _imputed_raw(row, base)
            mu_base = float(np.mean(mu[idxs]))
            items.append((base, dp_sum, raw_val, mu_base))
        
        items.sort(key=lambda t: abs(t[1]), reverse=True)
        return items[:topn], D2, _p_of_D2(D2), slope
    except Exception:
        return [], float("nan"), float("nan"), 0.0

def _fmt_raw(v):
    if pd.isna(v):
        return "nan"
    try:
        return f"{float(v):.3g}"
    except Exception:
        return str(v)

def topk_prob_attribution(row: pd.Series, topk: int = 3):
    items_all, D2, p_hat, slope = explain_hdbscan_local_influence_prob(row, topn=10_000)
    
    model_prob = row.get("_anom_proba", np.nan)
    if not np.isfinite(model_prob):
        st = row.get("_hdb_strength", np.nan)
        model_prob = (1.0 - float(st)) if np.isfinite(st) else np.nan
    
    pos = [(f, max(0.0, dp), raw_val, mu, dp) for (f, dp, raw_val, mu) in items_all]
    S = sum(v for _, v, _, _, _ in pos)
    if S == 0:
        pos = [(f, abs(dp), raw_val, mu, dp) for (f, dp, raw_val, mu) in items_all]
        S = sum(v for _, v, _, _, _ in pos)
    
    out = []
    if np.isfinite(model_prob) and S > 0:
        for f, v, raw_val, mu, dp in pos:
            share = model_prob * (v / S)
            out.append((f, float(share), _fmt_raw(raw_val), mu, float(dp)))
        out.sort(key=lambda t: t[1], reverse=True)
        return out[:topk], float(model_prob)
    
    return [], float(model_prob) if np.isfinite(model_prob) else float("nan")

def _fmt_time(ts):
    try:
        return pd.to_datetime(ts).strftime("%Y-%m-%d %H:%M:%S")
    except Exception:
        return "-"

# ==================== ì„±ëŠ¥ ê³„ì‚° ====================
try:
    if defect_model is None:
        raise ValueError("shared.pyì—ì„œ ëª¨ë¸ì„ ë¡œë“œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    
    split_index = int(len(train_df) * 0.8)
    valid_df = train_df.iloc[split_index:].copy().reset_index(drop=True)
    
    if TARGET_COL not in valid_df.columns:
        print(f"Warning: Validation ë°ì´í„°ì— '{TARGET_COL}' ì»¬ëŸ¼ì´ ì—†ì–´ ì„±ëŠ¥ ê³„ì‚°ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
    else:
        X_valid = valid_df[feature_cols]
        y_valid = valid_df[TARGET_COL]
        y_pred_proba = defect_model.predict_proba(X_valid)[:, 1]
        y_pred = (y_pred_proba >= PREDICTION_THRESHOLD).astype(int)
        tn, fp, fn, tp = confusion_matrix(y_valid, y_pred, labels=[0, 1]).ravel()
        validation_recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0
        validation_precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0
        
        recalls_per_chunk, precisions_per_chunk = [], []
        for i in range(0, len(valid_df), CHUNK_SIZE):
            chunk = valid_df.iloc[i: i + CHUNK_SIZE]
            if len(chunk) < CHUNK_SIZE or chunk[TARGET_COL].sum() == 0:
                continue
            
            X_chunk = chunk[feature_cols]
            y_true_chunk = chunk[TARGET_COL]
            y_pred_proba_chunk = defect_model.predict_proba(X_chunk)[:, 1]
            y_pred_chunk = (y_pred_proba_chunk >= PREDICTION_THRESHOLD).astype(int)
            tn_c, fp_c, fn_c, tp_c = confusion_matrix(y_true_chunk, y_pred_chunk, labels=[0, 1]).ravel()
            
            recalls_per_chunk.append(tp_c / (tp_c + fn_c) if (tp_c + fn_c) > 0 else 0.0)
            precisions_per_chunk.append(tp_c / (tp_c + fp_c) if (tp_c + fp_c) > 0 else 0.0)
        
        if len(recalls_per_chunk) > 1:
            mean_recall = np.mean(recalls_per_chunk)
            recall_lcl = max(0, mean_recall - 3 * np.sqrt(mean_recall * (1 - mean_recall) / CHUNK_SIZE))
        if len(precisions_per_chunk) > 1:
            mean_precision = np.mean(precisions_per_chunk)
            precision_lcl = max(0, mean_precision - 3 * np.sqrt(mean_precision * (1 - mean_precision) / CHUNK_SIZE))

except Exception as e:
    startup_error = f"ì´ˆê¸°í™” ì˜¤ë¥˜: {e}"

# ==================== P-ê´€ë¦¬ë„ ì¤€ë¹„ ====================
monitoring_vars = [
    'molten_temp', 'facility_operation_cycleTime', 'production_cycletime',
    'low_section_speed', 'high_section_speed', 'cast_pressure', 'biscuit_thickness',
    'upper_mold_temp1', 'upper_mold_temp2', 'lower_mold_temp1', 'lower_mold_temp2',
    'sleeve_temperature', 'physical_strength', 'Coolant_temperature'
]

var_stats = {}
for var in monitoring_vars:
    if var in train_df.columns:
        values = train_df[var].dropna()
        if len(values) > 0:
            mean = values.mean()
            std = values.std()
            var_stats[var] = {
                'mean': mean, 'std': std,
                'ucl': mean + 3 * std, 'lcl': mean - 3 * std
            }

if arima_stats:
    monitoring_vars = [var for var in monitoring_vars if var in arima_stats]

def calculate_p_values(df, var_stats):
    p_values = []
    for idx, row in df.iterrows():
        abnormal_count = 0
        valid_var_count = 0
        for var in var_stats.keys():
            if var in row and pd.notna(row[var]):
                valid_var_count += 1
                value = row[var]
                ucl = var_stats[var]['ucl']
                lcl = var_stats[var]['lcl']
                if value > ucl or value < lcl:
                    abnormal_count += 1
        p = abnormal_count / valid_var_count if valid_var_count > 0 else 0
        p_values.append(p)
    return np.array(p_values)

all_p_values = calculate_p_values(test_df, var_stats)
p_bar = all_p_values.mean()
n = len(var_stats)
CL = p_bar
UCL = p_bar + 3 * np.sqrt(p_bar * (1 - p_bar) / n)
LCL = max(0, p_bar - 3 * np.sqrt(p_bar * (1 - p_bar) / n))

def check_nelson_rules(p_values, cl, ucl, lcl):
    violations = {'rule1': [], 'rule4': [], 'rule8': []}
    sigma = (ucl - cl) / 3 if (ucl-cl) > 0 else 0
    n = len(p_values)
    
    for i in range(n):
        if p_values[i] > ucl or p_values[i] < lcl:
            violations['rule1'].append(i)
        
        if i >= 13:
            alternating = True
            for j in range(i - 12, i):
                if j > 0:
                    diff1 = p_values[j + 1] - p_values[j]
                    diff2 = p_values[j] - p_values[j - 1]
                    if diff1 * diff2 >= 0:
                        alternating = False
                        break
            if alternating:
                violations['rule4'].append(i)
        
        if i >= 7 and sigma > 0:
            all_outside = True
            for j in range(i - 7, i + 1):
                if abs(p_values[j] - cl) <= sigma:
                    all_outside = False
                    break
            if all_outside:
                violations['rule8'].append(i)
    
    return violations

# ==================== Reactive ë³€ìˆ˜ ====================
streamer = reactive.Value(RealTimeStreamer(streaming_df))
current_data = reactive.Value(pd.DataFrame())
is_streaming = reactive.Value(False)
was_reset = reactive.Value(False)

defect_logs = reactive.Value(pd.DataFrame(columns=["Time", "ID", "Prob"]))
anom_logs = reactive.Value(pd.DataFrame(columns=["Time", "ID", "Proba"]))

latest_anomaly_status = reactive.Value(0)
latest_defect_status = reactive.Value(0)

r_feedback_data = reactive.Value(pd.DataFrame(columns=["ID", "Prediction", "Correct", "Feedback"]))
r_correct_status = reactive.Value(None)

realtime_performance = reactive.Value(pd.DataFrame(columns=["Chunk", "Recall", "Precision", "TN", "FP", "FN", "TP"]))
latest_performance_metrics = reactive.Value({"recall": 0.0, "precision": 0.0})
last_processed_count = reactive.Value(0)

performance_degradation_status = reactive.Value({"degraded": False})
cumulative_cm_components = reactive.Value({"tp": 0, "fn": 0, "fp": 0})
cumulative_performance = reactive.Value({"recall": 0.0, "precision": 0.0})

recall_tooltip = reactive.Value(None)
precision_tooltip = reactive.Value(None)

ks_test_results = reactive.Value(pd.DataFrame(columns=["Count", "Feature", "PValue"]))
chunk_snapshot_data = reactive.Value(pd.DataFrame())
data_drift_status = reactive.Value({"degraded": False, "feature": None})
last_drift_processed_count = reactive.Value(0)

p_chart_streaming = reactive.Value(False)
p_chart_current_index = reactive.Value(0)

chatbot_visible = reactive.Value(False)
r_ai_answer = reactive.Value("ì§ˆë¬¸ì„ ìž…ë ¥í•´ì£¼ì„¸ìš”.")
r_is_loading = reactive.Value(False)

# Gemini API ì„¤ì •
GEMINI_MODEL_NAME = 'gemini-2.5-flash'
try:
    API_KEY = "AIzaSyAJbO4gJXKf8HetBy6TKwD5fEqAllgX-nc"
    if API_KEY == "YOUR_API_KEY_HERE":
        raise KeyError("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    genai.configure(api_key=API_KEY)
except KeyError:
    startup_error = "GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì±—ë´‡ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    print(f"ERROR: {startup_error}")
except Exception as e:
    startup_error = f"Gemini API í‚¤ ì„¤ì • ì˜¤ë¥˜: {e}"
    print(f"ERROR: {startup_error}")

# ==================== UI ====================
app_ui = ui.page_fluid(
    ui.tags.style("""
        body { overflow-y: auto !important; }
        .card-body { overflow-y: visible !important; }
        .plot-tooltip {
            position: absolute; background: rgba(0, 0, 0, 0.8); color: white;
            padding: 5px 10px; border-radius: 5px; pointer-events: none;
            z-index: 1000; font-size: 0.9rem;
        }
        .plot-tooltip table { color: white; border-collapse: collapse; }
        .plot-tooltip th, .plot-tooltip td { border: 1px solid #555; padding: 4px 8px; text-align: center; }
        .plot-tooltip th { background-color: #333; }
        .violation-item {
            padding: 12px; margin: 8px 0; border-left: 4px solid #dc3545;
            background-color: #fff5f5; border-radius: 4px;
        }
        .violation-header { font-weight: bold; color: #dc3545; margin-bottom: 6px; font-size: 14px; }
        .violation-detail { font-size: 13px; color: #666; margin: 4px 0; }
        .violation-rule {
            display: inline-block; padding: 2px 8px; margin: 2px;
            background-color: #dc3545; color: white; border-radius: 3px; font-size: 11px;
        }
        .btn-cause {
            margin-top: 8px; padding: 6px 12px; font-size: 12px;
            background-color: #007bff; color: white; border: none;
            border-radius: 4px; cursor: pointer;
        }
        .btn-cause:hover { background-color: #0056b3; }
        .violations-container { max-height: 1220px; overflow-y: auto; padding-right: 10px; }
        
        #chatbot_response .card-body { padding: 1.5rem; }
        #chatbot_response pre { 
            background-color: #f7f7f7; 
            padding: 10px; 
            border-radius: 5px; 
            overflow-x: auto;
        }
        
        table.custom-table {
            width: 100%;
            border-collapse: collapse;
            table-layout: fixed;
        }
        .custom-table th, .custom-table td {
            border: 1px solid #ccc;
            padding: 8px;
            text-align: center;
            word-wrap: break-word;
        }
        .custom-table th {
            background-color: #f5f5f5;
        }
        .custom-table td:nth-child(1) { width: 10%; }
        .custom-table td:nth-child(2) { width: 20%; }
        .custom-table td:nth-child(3) { width: 20%; }
        .custom-table td:nth-child(4) { width: 50%; text-align: left; }
    """),
    ui.tags.script("""
        function scrollToArima() {
            setTimeout(function() {
                const arimaCard = document.getElementById('arima_chart_card');
                if (arimaCard) {
                    arimaCard.scrollIntoView({ behavior: 'smooth', block: 'center' });
                }
            }, 100);
        }
    """),

    ui.h2("ì‹¤ì‹œê°„ í’ˆì§ˆ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ", class_="text-center fw-bold my-3"),
    
    ui.navset_card_tab(
        # ==================== íƒ­ 1: ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ====================
        ui.nav_panel("ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§",
            ui.div(
                {"class": "d-flex align-items-center gap-3 mb-3 sticky-top bg-light p-2 shadow-sm"},
                ui.input_action_button("start", "â–¶ ì‹œìž‘", class_="btn btn-success"),
                ui.input_action_button("pause", "â¸ ì¼ì‹œì •ì§€", class_="btn btn-warning"),
                ui.input_action_button("reset", "ðŸ”„ ë¦¬ì…‹", class_="btn btn-secondary"),
                ui.output_ui("stream_status"),
            ),
            ui.div(ui.p(f"âš ï¸ {startup_error}", style="color:red; font-weight:bold;") if startup_error else ""),

            ui.card(
                ui.card_header("ðŸ§­ ë³€ìˆ˜ ì„ íƒ"),
                ui.h5("í™•ì¸í•  ë³€ìˆ˜ ì„ íƒ"),
                ui.input_checkbox_group(
                    "selected_sensors", None,
                    choices={
                       "cast_pressure": "ì£¼ì¡°ì••",
                        "upper_mold_temp1": "ìƒë¶€ê¸ˆí˜•ì˜¨ë„",
                        "lower_mold_temp2": "í•˜ë¶€ê¸ˆí˜•ì˜¨ë„",
                        "low_section_speed": "ì €ì†êµ¬ê°„ì†",
                        "lower_mold_temp1": "í•˜ë¶€ê¸ˆí˜•ì˜¨ë„",
                        "sleeve_temperature": "ìŠ¬ë¦¬ë¸Œì˜¨",
                        "high_section_speed": "ê³ ì†êµ¬ê°„ì†",
                        "upper_mold_temp2": "ìƒë¶€ê¸ˆí˜•ì˜¨ë„",
                        "biscuit_thickness": "ë¹„ìŠ¤í‚·ë‘ê»˜",
                        "facility_operation_cycleTime": "ì„¤ë¹„ìž‘ë™ì‚¬ì´í´ì‹œê°„",
                        "Coolant_temperature": "ëƒ‰ê°ìˆ˜ì˜¨ë„",
                        "production_cycletime": "ìƒì‚°ì‚¬ì´í´ì‹œê°„",
                        "molten_temp": "ìš©íƒ•ì˜¨ë„",
                        "molten_volume": "ìš©íƒ•ëŸ‰",
                        "physical_strength": "ë¬¼ë¦¬ì ê°•ë„"
                    },
                    selected=["molten_temp", "cast_pressure"],
                    inline=True
                ),
                ui.h5("ëª°ë“œì½”ë“œ ì„ íƒ"),
                ui.input_checkbox_group(
                    "selected_molds", None,
                    choices={"ALL":"ALL","8412":"8412","8573":"8573","8600":"8600","8722":"8722","8917":"8917","8413":"8413","8576":"8576"},
                    selected=["ALL"], inline=True
                ),
            ),

            ui.div(
                {"class": "d-flex justify-content-around align-items-center flex-wrap mt-3"},
                ui.div([ui.span("ðŸ“… ìµœì‹  ìˆ˜ì‹  ì‹œê°: "), ui.output_text("latest_timestamp_text")],
                       class_="text-center my-2", style="font-size: 16px; font-weight: bold;"),
                ui.div([ui.div("ì´ìƒì¹˜ ìƒíƒœ", class_="fw-bold text-center mb-1"), ui.output_ui("anomaly_status_ui")],
                       class_="text-center mx-3"),
                ui.div([ui.div("ë¶ˆëŸ‰ íŒì •", class_="fw-bold text-center mb-1"), ui.output_ui("defect_status_ui")],
                       class_="text-center mx-3"),
            ),

            ui.output_ui("realtime_graphs"),
            ui.card(ui.output_ui("defect_stats_ui")),

            ui.hr(),
            ui.card(
                ui.card_header("ëª¨ë¸ ì˜ˆì¸¡ ë¶ˆëŸ‰ í™•ì¸ ë° í”¼ë“œë°±"),
                ui.row(
                    ui.column(6,
                            ui.h4("ë¶ˆëŸ‰ ì œí’ˆ"),
                            ui.output_ui("prediction_output_ui"),
                            ),
                    ui.column(6,
                            ui.h4("ëˆ„ì  í”¼ë“œë°±"),
                            ui.output_ui("feedback_table"),
                            ),
                ),
            ),
        ),

        # ==================== íƒ­ 2: ì´ìƒ íƒì§€ (í†µí•©) UI ====================
        ui.nav_panel("ì´ìƒ íƒì§€",
            ui.div(
                {"style": "padding: 20px;"},
                ui.h4("ê³µì • ì´ìƒ íƒì§€ P-ê´€ë¦¬ë„ ë° ê°œë³„ ë³€ìˆ˜ ê´€ë¦¬ë„"),
                ui.p(f"ëª¨ë‹ˆí„°ë§ ë³€ìˆ˜: {len(var_stats)}ê°œ | ì´ ë°ì´í„°: {len(test_df):,}ê±´",
                     style="color: #666; margin-bottom: 20px;")
            ),

            ui.row(
                ui.column(7,
                    ui.card(
                        ui.card_header(ui.h4("ì´ìƒ ì˜ˆì¸¡ í™•ë¥  (ì‹¤ì‹œê°„)", style="margin: 0;")),
                        ui.output_plot("anom_proba_plot", height="220px")
                    )
                ),
                ui.column(5,
                    ui.card(
                        ui.card_header(ui.h4(f"ì´ìƒì¹˜ ë¡œê·¸ (th â‰¥ {ANOMALY_PROBA_THRESHOLD:.2f})", style="margin: 0;")),
                        ui.output_ui("anom_logs_ui")
                    )
                )
            ),

            ui.row(
                ui.column(8,
                    ui.card(
                        ui.card_header(
                            ui.div(
                                {"class": "d-flex justify-content-between align-items-center"},
                                ui.h4("P-ê´€ë¦¬ë„ (ê³µì • ì´ìƒ ë¹„ìœ¨)", style="margin: 0;"),
                                ui.div(
                                    {"style": "width: 250px;"},
                                    ui.input_slider("lot_size", "ë¡œíŠ¸(ì„œë¸Œê·¸ë£¹) í¬ê¸°:",
                                                   min=10, max=500, value=200, step=10, animate=False)
                                )
                            )
                        ),
                        ui.output_plot("control_chart", height="500px")
                    ),
                    ui.card(
                        {"id": "arima_chart_card"},
                        ui.card_header(ui.h5("ê°œë³„ ë³€ìˆ˜ ê´€ë¦¬ë„ (Auto ARIMA - ì‹¤ì œê°’)")),
                        ui.input_select(
                            "selected_variable",
                            "ëª¨ë‹ˆí„°ë§í•  ë³€ìˆ˜ ì„ íƒ",
                            choices=monitoring_vars if monitoring_vars else ["ì—†ìŒ"],
                            selected=monitoring_vars[0] if monitoring_vars else "ì—†ìŒ"
                        ),
                        ui.output_plot("arima_control_chart", height="500px")
                    )
                ),
                ui.column(4,
                    ui.card(
                        ui.card_header(ui.h4("ê´€ë¦¬ë„ì´ìƒíŒ¨í„´íƒì§€", style="margin: 0;")),
                        ui.div({"class": "violations-container"}, ui.output_ui("violations_list"))
                    )
                )
            ),
        ),

        # ==================== íƒ­ 3: ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ====================
        ui.nav_panel("ëª¨ë¸ ì„±ëŠ¥ í‰ê°€",
            ui.layout_columns(
                ui.card(
                    ui.card_header("ì‹¤ì‹œê°„ ì„±ëŠ¥ (Chunk=200)", class_="text-center fw-bold"),
                    ui.layout_columns(
                        ui.div(
                            ui.p("ìµœì‹  Recall"),
                            ui.h4(ui.output_text("latest_recall_text")),
                            style="background-color: #fff0f5; padding: 1rem; border-radius: 8px; text-align: center;"
                        ),
                        ui.div(
                            ui.p("ìµœì‹  Precision"),
                            ui.h4(ui.output_text("latest_precision_text")),
                            style="background-color: #fff8f0; padding: 1rem; border-radius: 8px; text-align: center;"
                        ),
                        col_widths=[6, 6]
                    )
                ),
                ui.card(
                    ui.card_header("ëˆ„ì  ì„±ëŠ¥ ì§€í‘œ", class_="text-center fw-bold"),
                    ui.layout_columns(
                        ui.div(
                            ui.p(f"ëˆ„ì  Recall (Valid = {validation_recall:.2%})"),
                            ui.h5(ui.output_text("cumulative_recall_text"), class_="text-center text-primary mt-1")
                        ),
                        ui.div(
                            ui.p(f"ëˆ„ì  Precision (Valid = {validation_precision:.2%})"),
                            ui.h5(ui.output_text("cumulative_precision_text"), class_="text-center text-success mt-1")
                        ),
                        col_widths=[6, 6]
                    ),
                ),
                col_widths=[6, 6]
            ),

            ui.layout_columns(
                 ui.card(
                     ui.card_header("ëª¨ë¸ ì„±ëŠ¥ ìƒíƒœ"),
                     ui.output_ui("model_performance_status_ui")
                 ),
                 ui.card(
                     ui.card_header("ë°ì´í„° ë“œë¦¬í”„íŠ¸ ìƒíƒœ"),
                     ui.output_ui("data_drift_status_ui")
                 ),
                 col_widths=[6, 6]
            ),

            ui.hr(),

            ui.layout_columns(
                ui.div(
                    ui.card(
                        ui.card_header(
                            ui.div("ì‹¤ì‹œê°„ ìž¬í˜„ìœ¨(Recall) ì¶”ì´",
                                 ui.tags.small("â€» pê´€ë¦¬ë„ ê¸°ì¤€, n=200", class_="text-muted ms-2 fw-normal"),
                                 class_="d-flex align-items-baseline")
                        ),
                        ui.div(
                            ui.output_plot("realtime_recall_plot", height="230px"),
                            ui.output_ui("recall_tooltip_ui"),
                            style="position: relative;"
                        )
                    ),
                    ui.card(
                        ui.card_header("ì‹¤ì‹œê°„ ì •ë°€ë„(Precision) ì¶”ì´"),
                        ui.div(
                            ui.output_plot("realtime_precision_plot", height="230px"),
                            ui.output_ui("precision_tooltip_ui"),
                            style="position: relative;"
                        )
                    )
                ),

                ui.div(
                    ui.card(
                        ui.card_header("ì‹¤ì‹œê°„ ë°ì´í„° ë¶„í¬ (KDE)"),
                        ui.layout_columns(
                            ui.input_select(
                                "drift_feature_select",
                                "íŠ¹ì„±(Feature) ì„ íƒ",
                                choices=drift_feature_choices,
                                selected=drift_feature_choices[0] if len(drift_feature_choices) > 0 else None
                            ),
                            ui.div(
                                {"style": "display: flex; align-items: flex-end;"},
                                ui.p("í•™ìŠµ vs ì‹¤ì‹œê°„(100ê°œ) ë°ì´í„° ë¶„í¬ ë¹„êµ.",
                                     class_="text-muted small", style="margin-bottom: 0.5rem;")
                            ),
                            col_widths=[7, 5]
                        ),
                        ui.output_plot("drift_plot", height="230px")
                    ),
                    ui.card(
                        ui.card_header("ë°ì´í„° ë¶„í¬ ë³€í™” (KS ê²€ì • P-value)"),
                         ui.layout_columns(
                            ui.input_select(
                                "ks_feature_select",
                                "íŠ¹ì„±(Feature) ì„ íƒ",
                                choices=drift_feature_choices,
                                selected=drift_feature_choices[0] if len(drift_feature_choices) > 0 else None
                            ),
                             ui.div(
                                 {"style": "display: flex; align-items: flex-end;"},
                                 ui.p("100ê°œ chunk ë‹¨ìœ„ KS ê²€ì • p-value ì¶”ì´.",
                                      class_="text-muted small", style="margin-bottom: 0.5rem;")
                             ),
                            col_widths=[7, 5]
                        ),
                        ui.output_plot("ks_test_plot", height="230px")
                    ),
                ),
                col_widths=[6, 6]
            )
        )
    ),

    # ================== ì±—ë´‡ ====================
    ui.TagList(
        ui.div(
            ui.input_action_button("toggle_chatbot", "ðŸ¤–",
                                 style=("position: fixed; bottom: 20px; right: 20px; width: 50px; height: 50px; "
                                        "border-radius: 25px; font-size: 24px; background-color: #4CAF50; color: white; "
                                        "border: none; cursor: pointer; box-shadow: 0 2px 5px rgba(0,0,0,0.3); z-index: 1000;")
                                 )
        ),
        ui.div(
            ui.output_ui("chatbot_popup"),
            id="chatbot_popup_wrapper"
        )
    )
)

# ==================== SERVER ====================
def server(input, output, session):
    # ==================== ê³µí†µ ì œì–´ ====================
    @reactive.effect
    @reactive.event(input.start)
    def _():
        is_streaming.set(True)
        was_reset.set(False)
        p_chart_streaming.set(True)

    @reactive.effect
    @reactive.event(input.pause)
    def _():
        is_streaming.set(False)
        p_chart_streaming.set(False)

    @reactive.effect
    @reactive.event(input.reset)
    def _():
        streamer().reset_stream()
        current_data.set(pd.DataFrame())
        defect_logs.set(pd.DataFrame(columns=["Time", "ID", "Prob"]))
        anom_logs.set(pd.DataFrame(columns=["Time", "ID", "Proba"]))
        latest_anomaly_status.set(0)
        latest_defect_status.set(0)
        r_feedback_data.set(pd.DataFrame(columns=["ID", "Prediction", "Correct", "Feedback"]))
        r_correct_status.set(None)
        realtime_performance.set(pd.DataFrame(columns=["Chunk", "Recall", "Precision", "TN", "FP", "FN", "TP"]))
        latest_performance_metrics.set({"recall": 0.0, "precision": 0.0})
        last_processed_count.set(0)
        is_streaming.set(False)
        was_reset.set(True)
        performance_degradation_status.set({"degraded": False})
        cumulative_cm_components.set({"tp": 0, "fn": 0, "fp": 0})
        cumulative_performance.set({"recall": 0.0, "precision": 0.0})
        ks_test_results.set(pd.DataFrame(columns=["Count", "Feature", "PValue"]))
        chunk_snapshot_data.set(pd.DataFrame())
        data_drift_status.set({"degraded": False, "feature": None})
        last_drift_processed_count.set(0)
        p_chart_streaming.set(False)
        p_chart_current_index.set(0)
        r_ai_answer.set("ì§ˆë¬¸ì„ ìž…ë ¥í•´ì£¼ì„¸ìš”.")

    @output
    @render.ui
    def stream_status():
        status, color = ("ðŸ”´ ì¼ì‹œ ì •ì§€ë¨", "red")
        mold_text = "ì „ì²´ ëª°ë“œì½”ë“œ í‘œì‹œ ì¤‘"

        if was_reset():
            status, color = ("ðŸŸ¡ ë¦¬ì…‹ë¨", "orange")
        elif is_streaming():
            status, color = ("ðŸŸ¢ ê³µì • ì§„í–‰ ì¤‘", "green")

        molds = input.selected_molds()
        if molds:
            mold_text = f"ì„ íƒëœ ëª°ë“œì½”ë“œ: {', '.join(molds)}"

        return ui.div(
            f"{status} | {mold_text}",
            style=f"font-weight:bold; color:{color}; margin-left:15px;"
        )

    # ==================== ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ====================
    @reactive.effect
    def _():
        try:
            if not is_streaming():
                return

            reactive.invalidate_later(0.5)
            s = streamer()
            next_batch = s.get_next_batch(1)

            if next_batch is not None:
                current_stream_idx = s.current_index - 1
                original_df_idx = s.full_data.index[current_stream_idx]

                # ----- HDBSCAN ì´ìƒì¹˜ ì˜ˆì¸¡ -----
                try:
                    single_row_df = s.full_data.iloc[[current_stream_idx]]
                    ana_res = predict_anomaly(single_row_df)

                    if ana_res is not None and not ana_res.empty:
                        aprob_eff, strength = _effective_anom_proba(ana_res)
                        sev = 1 if aprob_eff >= ANOMALY_PROBA_THRESHOLD else 0

                        s.full_data.loc[original_df_idx, "_anom_proba"] = aprob_eff
                        s.full_data.loc[original_df_idx, "_hdb_strength"] = strength
                        s.full_data.loc[original_df_idx, "anomaly_status"] = sev
                        latest_anomaly_status.set(sev)

                        if sev == 1:
                            logs = anom_logs()
                            if logs.empty or (original_df_idx not in logs["ID"].tolist()):
                                ts = s.full_data.loc[original_df_idx, "registration_time"] \
                                    if "registration_time" in s.full_data.columns else pd.NaT
                                new_row = pd.DataFrame({"Time":[ts], "ID":[original_df_idx], "Proba":[aprob_eff]})
                                anom_logs.set(pd.concat([logs, new_row], ignore_index=True))
                except Exception as e:
                    print(f"âš ï¸ ì´ìƒì¹˜ ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")

                # ----- ë¶ˆëŸ‰ ì˜ˆì¸¡ -----
                if defect_model is not None:
                    latest_row = s.full_data.iloc[[current_stream_idx]].copy()
                    for col in feature_cols:
                        if col not in latest_row.columns:
                            latest_row[col] = 0
                    try:
                        prob = defect_model.predict_proba(latest_row[feature_cols])[0, 1]
                        pred = 1 if prob >= PREDICTION_THRESHOLD else 0
                    except Exception as e:
                        print(f"âš ï¸ ëª¨ë¸ ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
                        prob, pred = 0.0, 0

                    s.full_data.loc[original_df_idx, "defect_status"] = int(pred)
                    latest_defect_status.set(int(pred))

                    if int(pred) == 1:
                        logs = defect_logs()
                        if logs.empty or original_df_idx not in logs['ID'].values:
                            new_log = pd.DataFrame({
                                "Time": [s.full_data.loc[original_df_idx, "registration_time"]],
                                "ID": [original_df_idx],
                                "Prob": [prob]
                            })
                            defect_logs.set(pd.concat([logs, new_log], ignore_index=True))

                # í™”ë©´ ë°ì´í„° ì—…ë°ì´íŠ¸
                current_data.set(s.get_current_data())

                # ----- ì„±ëŠ¥ ì§‘ê³„ -----
                df_now = current_data()
                current_count = len(df_now)
                last_count = last_processed_count()
                
                if current_count // CHUNK_SIZE > last_count // CHUNK_SIZE:
                    chunk_number = current_count // CHUNK_SIZE
                    start_idx, end_idx = (chunk_number - 1) * CHUNK_SIZE, chunk_number * CHUNK_SIZE
                    
                    if len(test_label_df) >= end_idx:
                        chunk_data = df_now.iloc[start_idx:end_idx]
                        y_true_chunk = test_label_df.iloc[start_idx:end_idx][TARGET_COL].values
                        X_chunk = chunk_data[feature_cols]
                        y_pred_proba_chunk = defect_model.predict_proba(X_chunk)[:, 1]
                        y_pred_chunk = (y_pred_proba_chunk >= PREDICTION_THRESHOLD).astype(int)
                        
                        if len(np.unique(y_true_chunk)) > 1:
                            tn_c, fp_c, fn_c, tp_c = confusion_matrix(y_true_chunk, y_pred_chunk, labels=[0, 1]).ravel()
                        else:
                            if np.unique(y_true_chunk)[0] == 0:
                                tn_c = (y_pred_chunk == 0).sum()
                                fp_c = (y_pred_chunk == 1).sum()
                                fn_c = 0
                                tp_c = 0
                            else:
                                tn_c = 0
                                fp_c = 0
                                fn_c = (y_pred_chunk == 0).sum()
                                tp_c = (y_pred_chunk == 1).sum()

                        chunk_recall = tp_c / (tp_c + fn_c) if (tp_c + fn_c) > 0 else 0.0
                        chunk_precision = tp_c / (tp_c + fp_c) if (tp_c + fp_c) > 0 else 0.0

                        new_perf = pd.DataFrame({
                            "Chunk": [chunk_number], "Recall": [chunk_recall], "Precision": [chunk_precision],
                            "TN": [tn_c], "FP": [fp_c], "FN": [fn_c], "TP": [tp_c]
                        })
                        updated_perf = pd.concat([realtime_performance(), new_perf], ignore_index=True)
                        realtime_performance.set(updated_perf)
                        latest_performance_metrics.set({"recall": chunk_recall, "precision": chunk_precision})

                        cum_comps = cumulative_cm_components()
                        new_comps = {"tp": cum_comps["tp"] + tp_c, "fn": cum_comps["fn"] + fn_c, "fp": cum_comps["fp"] + fp_c}
                        cumulative_cm_components.set(new_comps)

                        cum_recall = new_comps["tp"] / (new_comps["tp"] + new_comps["fn"]) if (new_comps["tp"] + new_comps["fn"]) > 0 else 0.0
                        cum_precision = new_comps["tp"] / (new_comps["tp"] + new_comps["fp"]) if (new_comps["tp"] + new_comps["fp"]) > 0 else 0.0
                        cumulative_performance.set({"recall": cum_recall, "precision": cum_precision})

                        if len(updated_perf) >= 3:
                            last_three_recalls = updated_perf["Recall"].tail(3)
                            last_three_precisions = updated_perf["Precision"].tail(3)

                            recall_degraded = (last_three_recalls < recall_lcl).all()
                            precision_degraded = (last_three_precisions < precision_lcl).all()

                            performance_degradation_status.set({"degraded": recall_degraded or precision_degraded})
                    
                    last_processed_count.set(current_count)

                # ë°ì´í„° ë“œë¦¬í”„íŠ¸ í‰ê°€
                last_drift_count = last_drift_processed_count()
                if current_count // DRIFT_CHUNK_SIZE > last_drift_count // DRIFT_CHUNK_SIZE:
                    drift_chunk_number = current_count // DRIFT_CHUNK_SIZE
                    start_idx = (drift_chunk_number - 1) * DRIFT_CHUNK_SIZE
                    end_idx = drift_chunk_number * DRIFT_CHUNK_SIZE

                    current_drift_chunk = df_now.iloc[start_idx:end_idx].copy()

                    if not current_drift_chunk.empty:
                        new_ks_results = []
                        for feature in drift_feature_choices:
                            if feature in train_df.columns and feature in current_drift_chunk.columns:
                                train_vals = train_df[feature].dropna()
                                rt_vals = current_drift_chunk[feature].dropna() 

                                if len(train_vals) > 1 and len(rt_vals) > 1:
                                    try:
                                        ks_stat, p_value = ks_2samp(train_vals, rt_vals)
                                        new_ks_results.append({
                                            "Count": end_idx,
                                            "Feature": feature,
                                            "PValue": p_value
                                        })
                                    except Exception as ks_e:
                                        print(f"âš ï¸ KS ê²€ì • ì˜¤ë¥˜ ({feature}): {ks_e}")

                        if new_ks_results:
                            ks_df = ks_test_results()
                            ks_test_results.set(pd.concat([ks_df, pd.DataFrame(new_ks_results)], ignore_index=True))

                        drift_detected = False
                        drifting_feature = None
                        
                        if current_count >= 300: 
                            all_ks_results = ks_test_results()
                            if not all_ks_results.empty:
                                for feature in drift_feature_choices:
                                    feature_history = all_ks_results[
                                        all_ks_results["Feature"] == feature
                                    ].sort_values(by="Count")

                                    if len(feature_history) >= 3:
                                        last_three_pvalues = feature_history["PValue"].tail(3)
                                        if (last_three_pvalues < 0.05).all():
                                            drift_detected = True
                                            drifting_feature = feature
                                            break
                        
                        data_drift_status.set({"degraded": drift_detected, "feature": drifting_feature})
                        chunk_snapshot_data.set(current_drift_chunk)
                    
                    last_drift_processed_count.set(current_count)

        except asyncio.CancelledError:
            return
        except Exception as e:
            print(f"âš ï¸ Streaming loop error: {e}")

    # ==================== íƒ­ 1: ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ UI ====================
    @output
    @render.text
    def latest_timestamp_text():
        df = current_data()
        if df.empty or "registration_time" not in df.columns:
            return "â³ ì•„ì§ ë°ì´í„° ì—†ìŒ"
        latest_time = pd.to_datetime(df["registration_time"], errors='coerce').max()
        if pd.isna(latest_time):
             return "â³ ìœ íš¨í•œ ì‹œê°„ ì—†ìŒ"
        return latest_time.strftime("%Y-%m-%d %H:%M:%S")

    @output
    @render.ui
    def anomaly_status_ui():
        _ = is_streaming()
        _ = current_data()
        st = latest_anomaly_status()
        label, color = {0: ("ì–‘í˜¸", "#28a745"), 1: ("ê²½ê³ ", "#ffc107")}.get(st, ("-", "gray"))
        return ui.div(label, class_="text-white fw-bold text-center",
                      style=f"background:{color}; padding:8px 18px; border-radius:10px;")

    @output
    @render.ui
    def defect_status_ui():
        _ = is_streaming()
        _ = current_data()
        st = latest_defect_status()
        label, color = {0: ("ì–‘í’ˆ", "#28a745"), 1: ("ë¶ˆëŸ‰", "#dc3545")}.get(st, ("-", "gray"))
        return ui.div(label, class_="text-white fw-bold text-center",
                      style=f"background:{color}; padding:8px 18px; border-radius:10px;")

    def get_realtime_stats(df: pd.DataFrame):
        if df.empty:
            return {
                "total": 0, "anomaly_rate": 0.0, "anomaly_count": 0,
                "defect_rate": 0.0, "today_defect_rate": 0.0, 
                "defect_accuracy": 0.0, "goal_progress": 0.0, "goal_current": 0, "goal_target": 0
            }

        total = len(df)

        # ì´ìƒì¹˜ ì¹´ìš´íŠ¸ (anom_proba ê¸°ë°˜)
        ap = None
        if "_anom_proba" in df.columns:
            ap_try = pd.to_numeric(df["_anom_proba"], errors="coerce")
            if np.isfinite(ap_try).any() and float(np.nanmax(ap_try)) > 0.0:
                ap = ap_try

        if ap is None and "_hdb_strength" in df.columns:
            st = pd.to_numeric(df["_hdb_strength"], errors="coerce")
            if st.notna().any():
                ap = 1.0 - st

        if ap is None:
            anomaly_count = int((pd.to_numeric(df.get("anomaly_status"), errors="coerce").fillna(0) == 1).sum())
        else:
            anomaly_count = int((ap >= ANOMALY_PROBA_THRESHOLD).sum())

        anomaly_rate = (anomaly_count / total) * 100.0 if total > 0 else 0.0

        defect_rate = (
            pd.to_numeric(df.get("defect_status", 0), errors="coerce").fillna(0).astype(int).eq(1).mean() * 100
            if "defect_status" in df.columns else 0.0
        )

        today_defect_rate = 0.0
        if "registration_time" in df.columns:
            try:
                times_coerced = pd.to_datetime(df["registration_time"], errors="coerce")
                today = pd.Timestamp.now().normalize()
                df_today = df[times_coerced >= today]
                if not df_today.empty:
                    today_defect_rate = (
                        pd.to_numeric(df_today.get("defect_status", 0), errors="coerce").fillna(0).astype(int).eq(1).mean() * 100
                    )
            except Exception as e:
                print(f"âš ï¸ today_defect_rate ê³„ì‚° ì˜¤ë¥˜: {e}")
                today_defect_rate = 0.0

        defect_accuracy = 0.0
        try:
            if not df.empty and not test_label_df.empty:
                current_indices = df.index
                if len(test_label_df) >= len(current_indices):
                    valid_indices = test_label_df.index.intersection(current_indices)
                    if not valid_indices.empty:
                        relevant_labels = test_label_df.loc[valid_indices, [TARGET_COL]]
                        merged = df.loc[valid_indices].join(relevant_labels, how="inner")
                    
                        if "defect_status" in merged.columns and TARGET_COL in merged.columns:
                            y_true = merged[TARGET_COL].astype(int)
                            y_pred = merged["defect_status"].astype(int)
                            correct = (y_true == y_pred).sum()
                            if len(merged) > 0:
                                defect_accuracy = (correct / len(merged)) * 100
        except Exception as e:
            print(f"âš ï¸ defect_accuracy ê³„ì‚° ì˜¤ë¥˜: {e}")
            defect_accuracy = 0.0

        goal_progress = 0.0
        goal_target = 0
        try:
            if "hour" in train_df.columns:
                total_len = len(train_df)
                daily_counts = total_len / 24  
                goal_target = int(round(daily_counts))
            else:
                goal_target = 100

            if goal_target > 0:
                goal_progress = (len(df) / goal_target) * 100
                goal_progress = min(goal_progress, 100.0)
        except Exception as e:
            print(f"âš ï¸ ëª©í‘œ ë‹¬ì„±ë¥  ê³„ì‚° ì˜¤ë¥˜: {e}")
            goal_progress = 0.0
            goal_target = 0

        return {
            "total": total,
            "anomaly_rate": anomaly_rate,
            "anomaly_count": anomaly_count,
            "defect_rate": defect_rate,
            "today_defect_rate": today_defect_rate,
            "defect_accuracy": defect_accuracy,
            "goal_progress": goal_progress,
            "goal_current": len(df),
            "goal_target": goal_target
        }
        
    @output
    @render.ui
    def defect_stats_ui():
        df = current_data()
        stats = get_realtime_stats(df)

        total_count = stats.get("total", 0)
        anomaly_count = stats.get("anomaly_count", 0)
        correct_count = int(total_count * stats["defect_accuracy"] / 100) if total_count > 0 else 0

        return ui.layout_columns(
            ui.div(
                ui.h5("ì´ìƒì¹˜ íƒì§€"),
                ui.h2(f"{stats['anomaly_rate']:.2f}%"),
                ui.p(f"(ì´ {total_count}ê°œ ì¤‘ {anomaly_count}ê°œ ì´ìƒ)"),
                class_="card text-white bg-primary text-center p-3",
                style="border-radius: 5px;"
            ),
            ui.div(
                ui.h5("ë¶ˆëŸ‰ íƒì§€"),
                ui.h2(f"{stats['defect_rate']:.2f}%"),
                ui.p(f"(ì´ {total_count}ê°œ ì¤‘ {int(total_count * stats['defect_rate'] / 100)}ê°œ ë¶ˆëŸ‰)"),
                class_="card text-white bg-success text-center p-3",
                style="border-radius: 5px;"
            ),
            ui.div(
                ui.h5("ëª¨ë¸ ì˜ˆì¸¡ ì •í™•ë„"),
                ui.h2(f"{stats['defect_accuracy']:.2f}%"),
                ui.p(f"(ì´ {total_count}ê°œ ì¤‘ {correct_count}ê°œ ì¼ì¹˜)"),
                class_="card text-white bg-danger text-center p-3",
                style="border-radius: 5px;"
            ),
            ui.div(
                ui.h5("ëª©í‘œ ë‹¬ì„±ë¥ "),
                ui.h2(f"{stats['goal_progress']:.2f}%"),
                ui.p(f"(ì´ {stats['goal_target']}ê°œ ì¤‘ {stats['goal_current']}ê°œ ì™„ë£Œ)"),
                class_="card bg-warning text-dark text-center p-3",
                style="border-radius: 5px;"
            ),
        )

    @output
    @render.ui
    def realtime_graphs():
        selected = input.selected_sensors()
        if not selected:
            return ui.div("í‘œì‹œí•  ì„¼ì„œë¥¼ ì„ íƒí•˜ì„¸ìš”.", class_="text-warning text-center p-3")

        return ui.div(
            {"class": "d-flex flex-column gap-2"},
            *[ui.card(
                ui.card_header(f"ðŸ“ˆ {col}"),
                ui.output_plot(f"plot_{col}", width="100%", height="150px")
            ) for col in selected]
        )

    def make_plot_output(col):
        @output(id=f"plot_{col}")
        @render.plot
        def _plot():
            df = current_data()
            fig, ax = plt.subplots(figsize=(5, 1.6))

            if df.empty or col not in df.columns or df[col].isnull().all():
                ax.text(0.5, 0.5, "ë°ì´í„° ì—†ìŒ", ha="center", va="center", fontsize=9)
                ax.set_xticks([])
                ax.set_yticks([])
            else:
                y = df[col].dropna().values
                if len(y) == 0:
                    ax.text(0.5, 0.5, "ë°ì´í„° ì—†ìŒ", ha="center", va="center", fontsize=9)
                    ax.set_xticks([])
                    ax.set_yticks([])
                else:
                    x = np.arange(len(y))
                    window_size = 50
                    if len(y) > window_size:
                        x_window = x[-window_size:]
                        y_window = y[-window_size:]
                    else:
                        x_window = x
                        y_window = y
                    
                    ax.plot(x_window, y_window, linewidth=1.5, color="#007bff", marker="o", markersize=3)
                    if len(x_window) > 0:
                        ax.scatter(x_window[-1], y_window[-1], color="red", s=25, zorder=5)
                        ax.set_xlim(x_window[0], x_window[-1])

                    ax.set_title(f"{col}", fontsize=9, pad=2)
                    ax.tick_params(axis="x", labelsize=7)
                    ax.tick_params(axis="y", labelsize=7)
                    ax.grid(True, linewidth=0.4, alpha=0.4)
            
            plt.tight_layout(pad=0.3)
            return fig
        return _plot

    for col in [
    "molten_temp", "cast_pressure", "low_section_speed",
    "high_section_speed", "biscuit_thickness", "Coolant_temperature", "upper_mold_temp1", "lower_mold_temp2", "lower_mold_temp1",
    "sleeve_temperature", "upper_mold_temp2", "facility_operation_cycleTime",
    "production_cycletime", "molten_volume", "physical_strength"]:
        make_plot_output(col)

    @output
    @render.ui
    def prediction_output_ui():
        logs = defect_logs()
        if logs.empty:
            return ui.div("í˜„ìž¬ ë¶ˆëŸ‰ ì œí’ˆì´ ì—†ìŠµë‹ˆë‹¤.", class_="text-muted text-center p-3")

        display_logs = logs.iloc[::-1].copy()

        if "Time" in display_logs.columns:
            display_logs["ì‹œê°„"] = pd.to_datetime(display_logs["Time"]).dt.strftime("%Y-%m-%d %H:%M:%S")
            display_logs = display_logs.drop(columns=["Time"])

        if "Prob" in display_logs.columns:
            display_logs["í™•ë¥ "] = (display_logs["Prob"] * 100).round(2).astype(str) + "%"
            display_logs = display_logs.drop(columns=["Prob"])

        rows_html = ""
        for _, row in display_logs.iterrows():
            id_val = row["ID"]
            time_val = row["ì‹œê°„"]
            prob_val = row["í™•ë¥ "]
            rows_html += f"""
                <tr onclick="Shiny.setInputValue('clicked_log_id', {id_val}, {{priority: 'event'}})" style="cursor:pointer;">
                    <td>{id_val}</td><td>{time_val}</td><td>{prob_val}</td>
                </tr>
            """

        table_html = f"""
            <table class="table table-sm table-striped table-hover text-center align-middle">
                <thead><tr><th>ID</th><th>ì‹œê°„</th><th>í™•ë¥ </th></tr></thead>
                <tbody>{rows_html}</tbody>
            </table>
        """

        return ui.div(
            ui.HTML(table_html),
            style="max-height: 300px; overflow-y: auto; overflow-x: auto;"
        )

    @reactive.effect
    @reactive.event(input.clicked_log_id)
    def show_log_detail_modal():
        log_id = input.clicked_log_id()
        logs = defect_logs()

        if logs.empty or log_id not in logs["ID"].values:
            ui.notification_show("âš ï¸ í•´ë‹¹ ID ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", duration=3, type="warning")
            return

        row = logs[logs["ID"] == log_id].iloc[0]
        time_val = pd.to_datetime(row["Time"]).strftime("%Y-%m-%d %H:%M:%S")
        prob_val = f"{row['Prob']*100:.2f}%"

        true_label = "ë°ì´í„° ì—†ìŒ"
        if not test_label_df.empty and "id" in test_label_df.columns:
            match = test_label_df[test_label_df["id"] == log_id]
            if not match.empty:
                val = int(match.iloc[0]["passorfail"])
                true_label = "ë¶ˆëŸ‰" if val == 1 else "ì–‘í’ˆ"

        ui.modal_show(
            ui.modal(
                ui.h4(f"ðŸ“„ ë¶ˆëŸ‰ ì œí’ˆ ìƒì„¸ (ID: {log_id})"),
                ui.p(f"ì‹œê°„: {time_val}"),
                ui.p(f"ì˜ˆì¸¡ í™•ë¥ : {prob_val}"),
                ui.hr(),
                ui.h5(f"ðŸ” ì‹¤ì œ ë¼ë²¨: {true_label}",
                       class_="fw-bold text-center",
                       style="color:#007bff; font-size:18px;"),
                ui.hr(),

                ui.div(
                    {"class": "d-flex justify-content-center gap-3 mt-3"},
                    ui.input_action_button("correct_btn", "âœ… ë¶ˆëŸ‰ ë§žìŒ (Correct)", class_="btn btn-success px-4 py-2"),
                    ui.input_action_button("incorrect_btn", "âŒ ë¶ˆëŸ‰ ì•„ë‹˜ (Incorrect)", class_="btn btn-danger px-4 py-2"),
                ),

                ui.input_text(f"feedback_note_{log_id}", "", placeholder="ì˜ˆ: ëƒ‰ê°ìˆ˜ì˜¨ë„ ê¸‰ë³€", width="100%"),
                ui.input_action_button("submit_btn", "ðŸ’¾ í”¼ë“œë°± ì €ìž¥", class_="btn btn-primary w-100 mt-3"),

                title="ë¶ˆëŸ‰ ìƒì„¸ í™•ì¸ ë° í”¼ë“œë°±",
                easy_close=True,
                footer=None
            )
        )
    
    @reactive.Effect
    @reactive.event(input.correct_btn)
    def set_correct():
        r_correct_status.set("âœ… ë¶ˆëŸ‰ ë§žìŒ")
        ui.notification_show("'ë¶ˆëŸ‰ ë§žìŒ' ì„ íƒë¨", duration=2, type="success")

    @reactive.Effect
    @reactive.event(input.incorrect_btn)
    def set_incorrect():
        r_correct_status.set("âŒ ë¶ˆëŸ‰ ì•„ë‹˜")
        ui.notification_show("'ë¶ˆëŸ‰ ì•„ë‹˜' ì„ íƒë¨", duration=2, type="error")

    @reactive.Effect
    @reactive.event(input.submit_btn)
    def save_feedback():
        correct_status = r_correct_status()
        log_id = input.clicked_log_id()

        feedback_input_id = f"feedback_note_{log_id}"
        
        feedback_text = ""
        try:
            feedback_text = getattr(input, feedback_input_id)()
        except Exception as e:
            print(f"í”¼ë“œë°± í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {e}")

        if correct_status is None:
            ui.notification_show("ðŸš¨ ì‹¤ì œ ë¶ˆëŸ‰ ì—¬ë¶€ë¥¼ ë¨¼ì € ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.", duration=3, type="warning")
            return

        if not feedback_text:
            ui.notification_show("âš ï¸ í”¼ë“œë°± ë‚´ìš©ì„ ìž…ë ¥í•´ì£¼ì„¸ìš”.", duration=3, type="warning")
            return

        new_feedback = pd.DataFrame({
            "ID": [log_id],
            "Prediction": ["ë¶ˆëŸ‰"],
            "Correct": [correct_status],
            "Feedback": [feedback_text]
        })

        df_old = r_feedback_data()
        df_new = pd.concat([df_old[df_old["ID"] != log_id], new_feedback], ignore_index=True)
        r_feedback_data.set(df_new)
        
        r_correct_status.set(None)

        ui.notification_show("âœ… í”¼ë“œë°±ì´ ì„±ê³µì ìœ¼ë¡œ ì €ìž¥ë˜ì—ˆìŠµë‹ˆë‹¤.", duration=3, type="success")
        ui.modal_remove()

    @output
    @render.ui
    def feedback_table():
        df_feedback = r_feedback_data()
        if df_feedback.empty:
            return ui.div("ì•„ì§ ì €ìž¥ëœ í”¼ë“œë°±ì´ ì—†ìŠµë‹ˆë‹¤.", class_="text-muted text-center p-3")

        if "ID" in df_feedback.columns:
            df_feedback = df_feedback.sort_values(by="ID", ascending=False)

        col_map = {
            "ID": "ID", "Prediction": "ì˜ˆì¸¡", "Correct": "ì •ë‹µ", "Feedback": "í”¼ë“œë°±"
        }
        df_feedback = df_feedback.rename(columns=col_map)
        df_feedback = df_feedback[col_map.values()]

        header = ui.tags.tr(*[ui.tags.th(col) for col in df_feedback.columns])
        rows = []
        for _, row in df_feedback.iterrows():
            correct_text = str(row.get("ì •ë‹µ", ""))
            correct_style = ""
            if "ë§žìŒ" in correct_text:
                correct_style = "background-color: #d4edda; color: #155724;"
            elif "ì•„ë‹˜" in correct_text:
                correct_style = "background-color: #f8d7da; color: #721c24; font-weight: bold;"
            tds = [
                ui.tags.td(str(row.get("ID", ""))),
                ui.tags.td(str(row.get("ì˜ˆì¸¡", ""))),
                ui.tags.td(correct_text, style=correct_style),
                ui.tags.td(str(row.get("í”¼ë“œë°±", "")))
            ]
            rows.append(ui.tags.tr(*tds))

        return ui.tags.div(
            ui.tags.table({"class": "custom-table"}, ui.tags.thead(header), ui.tags.tbody(*rows)),
            style="max-height: 300px; overflow-y: auto;"
        )

    # ==================== íƒ­ 2: P-ê´€ë¦¬ë„ UI ====================
    
    @reactive.effect
    def _():
        if not p_chart_streaming():
            return
        
        reactive.invalidate_later(0.5)
        
        df = current_data()
        if df.empty:
            return
        
        current_idx = p_chart_current_index()
        n_points = input.data_points()
        max_idx = max(0, len(df) - n_points)
        
        if current_idx < max_idx:
            new_idx = current_idx + 1
            p_chart_current_index.set(new_idx)
    
    @reactive.Calc
    def get_current_p_data():
        df = current_data()
        if df.empty:
            return [], 0, 0
        
        start = p_chart_current_index()
        n_points = input.data_points()
        end = min(start + n_points, len(df))
        
        lot_size = input.lot_size()
        
        # lot_size ë¯¸ë§Œì´ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜ (ìµœì†Œ 1ê°œ ìƒ˜í”Œ í•„ìš”)
        if end - start < lot_size:
            return [], start, end
        p_values = []
        
        # lot_size ë‹¨ìœ„ë¡œ ì´ìƒì¹˜ ë¹„ìœ¨ ê³„ì‚°
        for i in range(start, end, lot_size):
            chunk_end = min(i + lot_size, end)
            # ë§ˆì§€ë§‰ ì²­í¬ê°€ lot_sizeë³´ë‹¤ ìž‘ìœ¼ë©´ í¬í•¨
            if chunk_end - i < lot_size * 0.5:  # ì ˆë°˜ ë¯¸ë§Œì´ë©´ ì œì™¸
                break
            
            chunk = df.iloc[i:chunk_end]
            
            # anomaly_status ì»¬ëŸ¼ í™•ì¸
            if "anomaly_status" in chunk.columns:
                p = chunk["anomaly_status"].mean()
            elif "_anom_proba" in chunk.columns:
                # ëŒ€ì²´: _anom_probaê°€ threshold ì´ìƒì´ë©´ ì´ìƒì¹˜ë¡œ ê°„ì£¼
                p = (chunk["_anom_proba"] >= 0.7).mean()
            else:
                p = 0.0
            
            p_values.append(p)
        
        return p_values, start, end

    @reactive.Calc
    def get_violations():
        current_p, start, end = get_current_p_data()
        violations = check_nelson_rules(current_p, CL, UCL, LCL)
        violations_absolute = {
            'rule1': [idx + start for idx in violations['rule1']],
            'rule4': [idx + start for idx in violations['rule4']],
            'rule8': [idx + start for idx in violations['rule8']]
        }
        return violations_absolute, current_p

    # ==================== íƒ­ 2: ë Œë”ë§ í•¨ìˆ˜ ====================

    @output
    @render.plot
    def anom_proba_plot():
        df = current_data()
        fig, ax = plt.subplots(figsize=(12, 3.2))

        if df.empty:
            ax.text(0.5, 0.5, "â³ ë°ì´í„° ìˆ˜ì‹  ëŒ€ê¸° ì¤‘...", ha="center", va="center", color="gray")
            ax.axis("off")
            return fig

        y = pd.to_numeric(df.get("_anom_proba"), errors="coerce")
        x = pd.to_datetime(df["registration_time"], errors="coerce") if "registration_time" in df.columns else pd.Series(np.arange(len(df)))

        m = y.notna() & x.notna()
        x, y = x[m], y[m]

        use_fallback = (len(y) == 0) or ((np.nanmax(y.fillna(0)) == 0.0) and ("_hdb_strength" in df.columns))
        if use_fallback:
            y_strength = pd.to_numeric(df.get("_hdb_strength"), errors="coerce")
            x_time = pd.to_datetime(df.get("registration_time"), errors="coerce") if "registration_time" in df.columns else pd.Series(np.arange(len(df)))
            mk = y_strength.notna() & x_time.notna()
            x = x_time[mk]
            y = (1.0 - y_strength[mk]).fillna(0.0)

        window = 400
        if len(y) > window:
            x, y = x.iloc[-window:], y.iloc[-window:]

        if not x.empty:
            ax.plot(x, y, lw=1.2, label="_anom_proba")
            ax.axhline(ANOMALY_PROBA_THRESHOLD, linestyle="--", linewidth=1.0,
                       color="purple", label=f"th={ANOMALY_PROBA_THRESHOLD:.2f}")

            above = y >= ANOMALY_PROBA_THRESHOLD
            if above.any():
                ax.scatter(x[above], y[above], marker='x', s=48, linewidths=1.5,
                           color='red', label="Anomaly(>th)")

            ax.legend(loc="upper right", fontsize=8)
            fig.autofmt_xdate()
        else:
            ax.text(0.5, 0.5, "í‘œì‹œí•  ë°ì´í„° ì—†ìŒ", ha="center", va="center", color="gray")

        ax.set_title(f"ì´ìƒì¹˜ í™•ë¥  (ë§ˆì§€ë§‰ {len(y)}ê°œ)", fontsize=10)
        ax.set_xlabel("ì‹œê°„", fontsize=9)
        ax.set_ylabel("í™•ë¥ ", fontsize=9)
        ax.grid(True, alpha=0.3)
        plt.tight_layout()
        return fig


    @output
    @render.ui
    def anom_logs_ui():
        logs_df = anom_logs()
        if logs_df is None or getattr(logs_df, "empty", True):
            return ui.div("í˜„ìž¬ ì´ìƒì¹˜ ì—†ìŒ", class_="text-muted text-center p-3")

        logs_df = logs_df.copy().iloc[::-1]
        if "Time" in logs_df.columns:
            logs_df["ì‹œê°„"] = pd.to_datetime(logs_df["Time"]).dt.strftime("%Y-%m-%d %H:%M:%S")
        if "Proba" in logs_df.columns:
            logs_df["í™•ë¥ "] = (logs_df["Proba"] * 100).round(2).astype(str) + "%"

        rows = []
        for _, r in logs_df.iterrows():
            rid = int(r["ID"])
            ts = r.get("ì‹œê°„", "-")
            pr = r.get("í™•ë¥ ", "-")
            rows.append(
                ui.tags.tr(
                    {"style": "cursor:pointer;", "onclick": f"Shiny.setInputValue('anom_row_click', {rid}, {{priority: 'event'}})"},
                    ui.tags.td(str(rid)), ui.tags.td(str(ts)), ui.tags.td(str(pr)),
                )
            )

        table = ui.tags.table(
            {"class": "table table-sm table-hover table-striped mb-0"},
            ui.tags.thead(ui.tags.tr(ui.tags.th("ID"), ui.tags.th("ì‹œê°„"), ui.tags.th("í™•ë¥ "))),
            ui.tags.tbody(*rows),
        )
        return ui.div(table, style="max-height: 260px; overflow-y:auto; overflow-x:auto;")


    @reactive.effect
    @reactive.event(input.anom_row_click)
    def _show_anom_detail_modal():
        sel_id = input.anom_row_click()
        if sel_id is None:
            return
        s = streamer()
        fd = s.full_data
        if sel_id not in fd.index:
            return
        row = fd.loc[sel_id]
        proba = row.get("_anom_proba", np.nan)
        strength = row.get("_hdb_strength", np.nan)
        ts = _fmt_time(row.get("registration_time", None))

        try:
            top3, model_prob_eff = topk_prob_attribution(row, topk=3)
        except Exception:
            top3, model_prob_eff = [], row.get("_anom_proba", np.nan)

        if not top3:
            modal = ui.modal(
                ui.h4(f"ì´ìƒì¹˜ ìƒì„¸ (ID: {sel_id})"),
                ui.p(f"ì‹œê°„: {ts}"),
                ui.p(
                    f"ëª¨ë¸ ì´ìƒí™•ë¥ : {float(proba):.2%}" if np.isfinite(proba)
                    else (f"ëª¨ë¸ ì´ìƒí™•ë¥ : {(1.0 - float(strength)):.2%}" if np.isfinite(strength)
                        else "ëª¨ë¸ ì´ìƒí™•ë¥ : -")
                ),
                ui.hr(),
                ui.h5("ê°€ëŠ¥í•œ ì›ì¸ ë¶„ì„ ì¤‘..."),
                ui.p("ê·¼ì²˜ ì´ì›ƒ ê¸°ì¤€ìœ¼ë¡œ ëšœë ·í•œ íŽ¸ì°¨ ì—†ìŒ"),
                title="ì´ìƒì¹˜ ì›ì¸ ë¶„ì„",
                easy_close=True,
                footer=ui.input_action_button("anom_modal_close", "ë‹«ê¸°", class_="btn btn-secondary"),
                size="l",
            )
            ui.modal_show(modal)
            return

        pretty = []
        for f, share, raw_val, mu, dp in top3:
            arrow = "â†‘" if dp > 0 else "â†“"
            pretty.append(f"{f} {arrow} (ê¸°ì—¬={share*100:.2f}%, ê°’={raw_val})")

        modal = ui.modal(
            ui.h4(f"ì´ìƒì¹˜ ìƒì„¸ (ID: {sel_id})"),
            ui.p(f"ì‹œê°„: {ts}"),
            ui.p(f"ëª¨ë¸ ì´ìƒí™•ë¥ : {model_prob_eff:.2%}" if np.isfinite(model_prob_eff) else "ëª¨ë¸ ì´ìƒí™•ë¥ : -"),
            ui.hr(),
            ui.h5("ê°€ëŠ¥í•œ ì›ì¸ (TOP 3) â€” í˜„ìž¬ í™•ë¥  ê¸°ì—¬"),
            ui.tags.ul(*[ui.tags.li(line) for line in pretty]),
            title="ì´ìƒì¹˜ ì›ì¸ ë¶„ì„",
            easy_close=True,
            footer=ui.input_action_button("anom_modal_close", "ë‹«ê¸°", class_="btn btn-secondary"),
            size="l",
        )
        ui.modal_show(modal)


    @reactive.effect
    @reactive.event(input.anom_modal_close)
    def _close_anom_modal():
        ui.modal_remove()


    @output
    @render.plot(alt="P-Control Chart")
    def control_chart():
        current_p, start, end = get_current_p_data()
        violations_abs, _ = get_violations()

        lot_size = input.lot_size()

        fig, ax = plt.subplots(figsize=(12, 7))

        # ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°
        if len(current_p) == 0:
            df = current_data()
            if df.empty:
                msg = "ë°ì´í„° ìˆ˜ì§‘ ëŒ€ê¸° ì¤‘..."
            else:
                msg = f"ë°ì´í„° ìˆ˜ì§‘ ì¤‘... ({len(df)}/{lot_size}ê°œ, ìµœì†Œ 1ê°œ ìƒ˜í”Œ = {lot_size}ê°œ ë°ì´í„° í•„ìš”)"
            ax.text(0.5, 0.5, msg, ha="center", va="center", fontsize=14, color="gray")
            ax.axis('off')
            plt.close(fig)
            return fig

        # xì¶•ì€ ì‹¤ì œ ë°ì´í„° ì‹œì  (ARIMAì™€ ë™ì¼)
        x_values = np.arange(start, start + len(current_p) * lot_size, lot_size)

        ax.plot(x_values, current_p, 'o-', color='#1f77b4',
                linewidth=2, markersize=6, label='ì´ìƒ ë¹„ìœ¨ (p)', zorder=3)

        ax.axhline(y=CL, color='green', linewidth=2, linestyle='-', label=f'CL ({CL:.4f})')
        ax.axhline(y=UCL, color='red', linewidth=2, linestyle='--', label=f'UCL ({UCL:.4f})')
        ax.axhline(y=LCL, color='red', linewidth=2, linestyle='--', label=f'LCL ({LCL:.4f})')

        if (UCL - CL) > 0:
            sigma = (UCL - CL) / 3
            ax.axhline(y=CL + sigma, color='orange', linewidth=1, linestyle=':', alpha=0.5, label='+1Ïƒ')
            ax.axhline(y=CL - sigma, color='orange', linewidth=1, linestyle=':', alpha=0.5, label='-1Ïƒ')

        all_violations_set = set()
        for rule_violations in violations_abs.values():
            all_violations_set.update(rule_violations)

        # violationì€ ì‹¤ì œ ë°ì´í„° ì‹œì ìœ¼ë¡œ í‘œì‹œ
        if all_violations_set and len(current_p) > 0:
            for sample_idx in sorted(all_violations_set):
                if 0 <= sample_idx < len(current_p):
                    marker, color, size = 'x', 'red', 150

                    if sample_idx in violations_abs['rule1']:
                        color, marker, size = 'red', 'x', 200
                    elif sample_idx in violations_abs['rule8']:
                        color, marker, size = 'orange', 'D', 120
                    elif sample_idx in violations_abs['rule4']:
                        color, marker, size = 'purple', '*', 200

                    # ì‹¤ì œ ë°ì´í„° ì‹œì ìœ¼ë¡œ ë³€í™˜
                    actual_x = start + sample_idx * lot_size
                    ax.scatter([actual_x], [current_p[sample_idx]], marker=marker, s=size, c=color,
                                edgecolors='white', linewidths=2, zorder=5)

        ax.set_xlabel('ì‹œì  (ë°ì´í„° í¬ì¸íŠ¸)', fontsize=12, fontweight='bold')
        ax.set_ylabel('ì´ìƒ ë¹„ìœ¨ (p)', fontsize=12, fontweight='bold')

        ax.grid(True, alpha=0.3, linestyle='--')
        ax.legend(loc='upper right', fontsize=9, framealpha=0.9)

        y_margin = (UCL - LCL) * 0.1 if (UCL - LCL) > 0 else 0.01
        ax.set_ylim([max(0, LCL - y_margin), max(UCL + y_margin, np.max(current_p) * 1.1 if len(current_p) > 0 else UCL + y_margin)])

        plt.tight_layout()
        plt.close(fig)
        return fig


    @output
    @render.ui
    def violations_list():
        violations_abs, current_p = get_violations()
        start, end = get_current_p_data()[1:]

        all_violations = {}
        for rule, indices in violations_abs.items():
            for idx in indices:
                if start <= idx < end:
                    if idx not in all_violations:
                        all_violations[idx] = []
                    all_violations[idx].append(rule)

        if not all_violations:
            return ui.div(
                ui.p("âœ… í˜„ìž¬ ë²”ìœ„ì—ì„œ ê´€ë¦¬ë„ ì´ìƒíŒ¨í„´ íƒì§€ ìœ„ë°˜ì´ ì—†ìŠµë‹ˆë‹¤.",
                     style="color: #28a745; padding: 20px; text-align: center;")
            )

        sorted_violations = sorted(all_violations.items(), key=lambda x: x[0], reverse=True)
        violation_items = []

        rule_names = {
            'rule1': 'Rule 1: 3Ïƒ ì´ˆê³¼',
            'rule4': 'Rule 4: 14ê°œ ì—°ì† êµëŒ€',
            'rule8': 'Rule 8: 8ê°œ ì—°ì† Â±1Ïƒ ë°–'
        }

        rule_descriptions = {
            'rule1': 'ê´€ë¦¬í•œê³„ì„ (UCL/LCL)ì„ ë²—ì–´ë‚¨',
            'rule4': '14ê°œ ì´ìƒ ì ì´ ì—°ì†í•´ì„œ ìƒìŠ¹-í•˜ë½ì´ ë²ˆê°ˆì•„ ë‚˜íƒ€ë‚¨',
            'rule8': '8ê°œ ì—°ì† ì ì´ ëª¨ë‘ ì¤‘ì‹¬ì„ ì—ì„œ Â±1Ïƒ ë°–ì— ìœ„ì¹˜'
        }

        for idx, rules in sorted_violations:
            p_value = all_p_values[idx]

            abnormal_vars = []
            df = current_data()
            if not df.empty and idx < len(df):
                row = df.iloc[idx]
                for var in var_stats.keys():
                    if var in row and pd.notna(row[var]):
                        value = row[var]
                        ucl = var_stats[var]['ucl']
                        lcl = var_stats[var]['lcl']
                        if value > ucl or value < lcl:
                            abnormal_vars.append(var)

            rules_badges = [ui.span(rule_names[rule], class_="violation-rule") for rule in rules]
            rules_desc = [rule_descriptions[rule] for rule in rules]

            first_abnormal_var = abnormal_vars[0] if abnormal_vars else ""
            abnormal_vars_str = ', '.join(abnormal_vars) if abnormal_vars else 'ì—†ìŒ'

            onclick_js = f"""
                if ('{first_abnormal_var}') {{
                    Shiny.setInputValue('selected_variable', '{first_abnormal_var}', {{priority: 'event'}});
                    var dropdown = document.getElementById('selected_variable');
                    if (dropdown) {{ dropdown.value = '{first_abnormal_var}'; }}
                    scrollToArima();
                }}
                alert('ì‹œì  {idx}ì˜ ìƒì„¸ ë¶„ì„\\n\\nì´ìƒ ë¹„ìœ¨: {p_value:.2%}\\nìœ„ë°˜ ê·œì¹™: {', '.join([rule_names[r] for r in rules])}\\nì´ìƒ ë³€ìˆ˜: {abnormal_vars_str}');
            """

            violation_items.append(
                ui.div(
                    {"class": "violation-item"},
                    ui.div(f"âš ï¸ ì‹œì  {idx} (ì´ìƒ ë¹„ìœ¨: {p_value:.2%})", class_="violation-header"),
                    ui.div(*rules_badges, style="margin: 6px 0;"),
                    ui.div(
                        ui.tags.ul(
                            *[ui.tags.li(desc, style="font-size: 12px; color: #666;") for desc in rules_desc],
                            style="margin: 8px 0; padding-left: 20px;"
                        )
                    ),
                    ui.div(
                        f"ì´ìƒ ë³€ìˆ˜: {', '.join(abnormal_vars[:5])}" + ("..." if len(abnormal_vars) > 5 else ""),
                        class_="violation-detail"
                    ) if abnormal_vars else None,
                    ui.tags.button(
                        "ðŸ” ì´ìƒì›ì¸ ë¶„ì„",
                        class_="btn-cause",
                        onclick=onclick_js
                    )
                )
            )

        total_violations = len(sorted_violations)

        return ui.div(
            ui.div(
                f"ì´ {total_violations}ê±´ì˜ ìœ„ë°˜ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.",
                style="padding: 10px; background-color: #fff3cd; border-left: 4px solid #ffc107; margin-bottom: 15px; font-weight: bold;"
            ),
            *violation_items
        )


    @output
    @render.plot(alt="ARIMA Control Chart")
    def arima_control_chart():
        var_name = input.selected_variable()

        if not var_name or var_name not in arima_stats:
            fig, ax = plt.subplots(figsize=(12, 6))
            msg = "ARIMA í†µê³„ê°€ ì—†ìŠµë‹ˆë‹¤.\ntrain_arima_models.pyë¥¼ ì‹¤í–‰í•˜ì—¬\narima_stats.pkl íŒŒì¼ì„ ìƒì„±í•˜ì„¸ìš”."
            ax.text(0.5, 0.5, msg, ha="center", va="center", fontsize=12, color="gray")
            ax.axis('off')
            plt.close(fig)
            return fig

        df = current_data()
        if df.empty:
            fig, ax = plt.subplots(figsize=(12, 6))
            ax.text(0.5, 0.5, "ë°ì´í„° ìˆ˜ì‹  ëŒ€ê¸° ì¤‘...", ha="center", va="center", fontsize=12, color="gray")
            ax.axis('off')
            plt.close(fig)
            return fig

        start = p_chart_current_index()
        n_points = 50
        end = min(start + n_points, len(df))

        if var_name not in df.columns:
            fig, ax = plt.subplots(figsize=(12, 6))
            ax.text(0.5, 0.5, f"'{var_name}' ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", 
                    ha="center", va="center", fontsize=12, color="red")
            ax.axis('off')
            plt.close(fig)
            return fig

        actual_data = df[var_name].iloc[start:end].dropna()

        if len(actual_data) < 1:
            fig, ax = plt.subplots(figsize=(12, 6))
            ax.text(0.5, 0.5, "ë°ì´í„° ìˆ˜ì§‘ ëŒ€ê¸° ì¤‘...", 
                    ha="center", va="center", fontsize=12, color="gray")
            ax.axis('off')
            plt.close(fig)
            return fig

        try:
            stats = arima_stats[var_name]
            order = stats['order']
            aic = stats['aic']

            data_mean = stats['data_mean']
            ucl_data = stats['ucl_data']
            lcl_data = stats['lcl_data']
            data_std = stats['data_std']

            fig, ax = plt.subplots(figsize=(12, 6))

            x_values = np.arange(start, start + len(actual_data))

            ax.plot(x_values, actual_data.values, 'o-', color='#1f77b4', 
                    linewidth=2, markersize=4, label='ì‹¤ì œê°’', alpha=0.8)
            ax.axhline(y=data_mean, color='green', linewidth=2.5, linestyle='-', 
                       label=f'í‰ê·  (CL: {data_mean:.2f})')
            ax.axhline(y=ucl_data, color='red', linewidth=2.5, linestyle='--', 
                       label=f'UCL: {ucl_data:.2f}')
            ax.axhline(y=lcl_data, color='red', linewidth=2.5, linestyle='--', 
                       label=f'LCL: {lcl_data:.2f}')

            ax.axhline(y=data_mean + data_std, color='orange', linewidth=1, 
                       linestyle=':', alpha=0.5, label='+1Ïƒ')
            ax.axhline(y=data_mean - data_std, color='orange', linewidth=1, 
                       linestyle=':', alpha=0.5, label='-1Ïƒ')

            ooc_data = (actual_data.values > ucl_data) | (actual_data.values < lcl_data)
            if ooc_data.any():
                ax.scatter(x_values[ooc_data], actual_data.values[ooc_data], 
                           marker='x', s=200, c='red', edgecolors='white', 
                           linewidths=3, zorder=5, label='ðŸš¨ ê´€ë¦¬ ì´íƒˆ')

            ax.set_xlabel('ì‹œì  (ë°ì´í„° í¬ì¸íŠ¸)', fontsize=12, fontweight='bold')
            ax.set_ylabel(f'{var_name} ì¸¡ì •ê°’', fontsize=12, fontweight='bold')
            ax.legend(loc='upper right', fontsize=10, framealpha=0.9)
            ax.grid(True, alpha=0.3, linestyle='--')

            y_min = min(lcl_data, actual_data.min())
            y_max = max(ucl_data, actual_data.max())
            y_margin = (y_max - y_min) * 0.1
            ax.set_ylim([y_min - y_margin, y_max + y_margin])

            plt.tight_layout()
            plt.close(fig)
            return fig

        except Exception as e:
            fig, ax = plt.subplots(figsize=(12, 6))
            ax.text(0.5, 0.5, f"ì°¨íŠ¸ ìƒì„± ì˜¤ë¥˜: {str(e)}", 
                    ha="center", va="center", fontsize=12, color="red")
            ax.axis('off')
            plt.close(fig)
            return fig
        
    # ==================== íƒ­ 3: ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ====================
    @output
    @render.text
    def latest_recall_text():
        return f"{latest_performance_metrics.get()['recall']:.2%}"

    @output
    @render.text
    def latest_precision_text():
        return f"{latest_performance_metrics.get()['precision']:.2%}"

    @output
    @render.text
    def cumulative_recall_text():
        return f"{cumulative_performance.get()['recall']:.2%}"

    @output
    @render.text
    def cumulative_precision_text():
        return f"{cumulative_performance.get()['precision']:.2%}"

    @output
    @render.ui
    def model_performance_status_ui():
        status = performance_degradation_status.get()
        if status["degraded"]:
            bg_color = "#dc3545"
            title = "âš ï¸ ëª¨ë¸ ì„±ëŠ¥ ì €í•˜"
            body = "ìµœê·¼ ì„±ëŠ¥ ì§€í‘œê°€ ê´€ë¦¬ í•˜í•œì„ ì„ ì—°ì† ì´íƒˆí–ˆìŠµë‹ˆë‹¤. ëª¨ë¸ ìž¬í•™ìŠµ ë˜ëŠ” ì ê²€ì´ í•„ìš”í•©ë‹ˆë‹¤."
        else:
            bg_color = "#28a745"
            title = "âœ… ëª¨ë¸ ì„±ëŠ¥ ì–‘í˜¸"
            body = "ì •ìƒ ìž‘ë™ ì¤‘ìž…ë‹ˆë‹¤."

        return ui.div(
            ui.div(
                ui.h5(title, class_="card-title text-center text-white"),
                ui.hr(style="border-top: 1px solid white; opacity: 0.5; margin: 10px 0;"),
                ui.p(body, class_="card-text text-center text-white", style="font-size: 0.9rem;"),
                style=f"background-color: {bg_color}; padding: 15px; border-radius: 8px; min-height: 160px;",
                class_="d-flex flex-column justify-content-center"
            ),
            ui.p(
                "â€» ìµœê·¼ 3ê°œ ì²­í¬(n=200)ì˜ Recall ë˜ëŠ” Precisionì´ ì—°ì†ìœ¼ë¡œ LCL ë¯¸ë§Œì¼ ê²½ìš° 'ì„±ëŠ¥ ì €í•˜'ë¡œ í‘œì‹œë©ë‹ˆë‹¤.",
                class_="text-muted text-center",
                style="font-size: 0.75rem; margin-top: 8px;"
            )
        )

    @output
    @render.ui
    def data_drift_status_ui():
        status = data_drift_status.get()
        current_count = last_processed_count()

        note = f"â€» {DRIFT_CHUNK_SIZE * 3}ê°œ ë°ì´í„° ëˆ„ì  í›„, 100ê°œ ë‹¨ìœ„ P-valueê°€ 3íšŒ ì—°ì† 0.05 ë¯¸ë§Œì¼ ê²½ìš° 'ë“œë¦¬í”„íŠ¸ ì˜ì‹¬'ìœ¼ë¡œ í‘œì‹œë©ë‹ˆë‹¤."

        if current_count < (DRIFT_CHUNK_SIZE * 3):
            bg_color = "#6c757d"
            title = "ðŸ” ë°ì´í„° ìˆ˜ì§‘ ì¤‘"
            body = f"ë“œë¦¬í”„íŠ¸ ëª¨ë‹ˆí„°ë§ì€ {DRIFT_CHUNK_SIZE * 3}ê°œ ë°ì´í„° ìˆ˜ì§‘ í›„ ì‹œìž‘ë©ë‹ˆë‹¤. (í˜„ìž¬ {current_count}ê°œ)"
        elif status["degraded"]:
            bg_color = "#ffc107"
            title = "âš ï¸ ë°ì´í„° ë“œë¦¬í”„íŠ¸ ì˜ì‹¬"
            body = f"'{status.get('feature', 'N/A')}' ë³€ìˆ˜ ë¶„í¬ ë³€í™” ì˜ì‹¬. ì ê²€ í•„ìš”."
        else:
            bg_color = "#28a745"
            title = "âœ… ë°ì´í„° ë¶„í¬ ì–‘í˜¸"
            body = "ë°ì´í„° ë“œë¦¬í”„íŠ¸ ì§•í›„ê°€ ì—†ìŠµë‹ˆë‹¤."

        return ui.div(
            ui.div(
                ui.h5(title, class_="card-title text-center text-white"),
                ui.hr(style="border-top: 1px solid white; opacity: 0.5; margin: 10px 0;"),
                ui.p(body, class_="card-text text-center text-white", style="font-size: 0.9rem;"),
                style=f"background-color: {bg_color}; padding: 15px; border-radius: 8px; min-height: 160px;",
                class_="d-flex flex-column justify-content-center"
            ),
            ui.p(
                note,
                class_="text-muted text-center",
                style="font-size: 0.75rem; margin-top: 8px;"
            )
        )

    @output
    @render.plot(alt="Data Drift KDE Plot")
    def drift_plot():
        selected_col = input.drift_feature_select()
        rt_df = chunk_snapshot_data()
        fig, ax = plt.subplots()

        if rt_df.empty:
            ax.text(0.5, 0.5, f"ë°ì´í„° ìˆ˜ì§‘ ì¤‘... ({DRIFT_CHUNK_SIZE}ê°œ ë„ë‹¬ ì‹œ ì‹œìž‘)", ha="center", va="center", color="gray", fontsize=10)
            ax.axis('off')
        elif not selected_col or selected_col not in drift_feature_choices:
            ax.text(0.5, 0.5, "í‘œì‹œí•  ìœ íš¨í•œ íŠ¹ì„±ì„ ì„ íƒí•˜ì„¸ìš”.", ha="center", va="center", color="gray", fontsize=10)
            ax.axis('off')
        elif selected_col not in train_df.columns:
            ax.text(0.5, 0.5, f"'{selected_col}'ëŠ” í•™ìŠµ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤.", ha="center", va="center", color="orange", fontsize=10)
            ax.axis('off')
        else:
            try:
                train_series = train_df[selected_col].dropna()
                if not train_series.empty:
                    sns.kdeplot(train_series, ax=ax, label="í•™ìŠµ ë°ì´í„° (Train)", color="blue", fill=True, alpha=0.2, linewidth=1.5)
                else:
                    ax.text(0.5, 0.6, "í•™ìŠµ ë°ì´í„° ì—†ìŒ", ha="center", va="center", color="blue", alpha=0.5, fontsize=9)

                if selected_col in rt_df.columns:
                    rt_series = rt_df[selected_col].dropna()
                    if len(rt_series) > 1:
                        sns.kdeplot(rt_series, ax=ax, label=f"ì‹¤ì‹œê°„ (ìµœê·¼ {len(rt_series)}ê°œ)", color="red", linewidth=2, linestyle='-')
                    elif len(rt_series) == 1:
                        ax.axvline(rt_series.iloc[0], color="red", linestyle='--', linewidth=1.5, label="ì‹¤ì‹œê°„ (1ê°œ)")

                ax.set_xlabel(selected_col, fontsize=9)
                ax.set_ylabel("ë°€ë„ (Density)", fontsize=9)
                ax.legend(fontsize=8)
                ax.grid(True, alpha=0.3, linestyle=':')
                ax.tick_params(axis='both', which='major', labelsize=8)

            except Exception as e:
                print(f"Drift Plot Error for {selected_col}: {e}")
                ax.text(0.5, 0.5, f"í”Œë¡¯ ìƒì„± ì˜¤ë¥˜ ë°œìƒ", ha="center", va="center", color="red", fontsize=10)
                ax.axis('off')

        plt.tight_layout()
        return fig

    @output
    @render.plot(alt="KS Test P-value Trend Plot")
    def ks_test_plot():
        selected_ks_col = input.ks_feature_select()
        results_df = ks_test_results()
        fig, ax = plt.subplots()

        if not selected_ks_col or selected_ks_col not in drift_feature_choices:
            ax.text(0.5, 0.5, "P-value ì¶”ì´ë¥¼ ë³¼ íŠ¹ì„±ì„ ì„ íƒí•˜ì„¸ìš”.", ha="center", va="center", color="gray", fontsize=10)
            ax.axis('off')
        elif results_df.empty or results_df[results_df["Feature"] == selected_ks_col].empty:
            ax.text(0.5, 0.5, f"ì•„ì§ KS ê²€ì • ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\n(ë°ì´í„° {DRIFT_CHUNK_SIZE}ê°œ ë„ë‹¬ ì‹œ ì‹œìž‘)", ha="center", va="center", color="gray", fontsize=10)
            ax.axis('off')
            ax.set_xlim(0, DRIFT_CHUNK_SIZE * 2)
            ax.set_ylim(0, 0.2)
        else:
            try:
                feature_results = results_df[results_df["Feature"] == selected_ks_col].copy()
                feature_results = feature_results.sort_values(by="Count")

                ax.plot(feature_results["Count"], feature_results["PValue"], marker='o', linestyle='-', markersize=5, label='P-value')
                ax.axhline(y=0.05, color='red', linestyle='--', linewidth=1, label='ìœ ì˜ìˆ˜ì¤€ (0.05)')

                below_threshold = feature_results[feature_results["PValue"] < 0.05]
                if not below_threshold.empty:
                    ax.scatter(below_threshold["Count"], below_threshold["PValue"], color='red', s=50, zorder=5, label='P < 0.05')

                ax.set_xlabel("ë°ì´í„° ìˆ˜ì§‘ ì‹œì  (ê°œìˆ˜)", fontsize=9)
                ax.set_ylabel("P-value", fontsize=9)
                ax.set_ylim(0, 0.2)

                min_x, max_x = feature_results["Count"].min(), feature_results["Count"].max()
                x_margin = max(DRIFT_CHUNK_SIZE * 0.5, (max_x - min_x) * 0.05)
                ax.set_xlim(max(0, min_x - x_margin), max_x + x_margin)

                handles, labels = ax.get_legend_handles_labels()
                by_label = dict(zip(labels, handles))
                ax.legend(by_label.values(), by_label.keys(), fontsize=8)

                ax.grid(True, alpha=0.3, linestyle=':')
                ax.tick_params(axis='both', which='major', labelsize=8)

            except Exception as e:
                print(f"KS Plot Error for {selected_ks_col}: {e}")
                ax.text(0.5, 0.5, f"í”Œë¡¯ ìƒì„± ì˜¤ë¥˜ ë°œìƒ", ha="center", va="center", color="red", fontsize=10)
                ax.axis('off')

        plt.tight_layout()
        return fig

    @output
    @render.plot(alt="Real-time Recall Trend Plot")
    def realtime_recall_plot():
        perf_df = realtime_performance()
        fig, ax = plt.subplots()
        if perf_df.empty:
            ax.text(0.5, 0.5, "ë°ì´í„° ìˆ˜ì§‘ ì¤‘...", ha="center", va="center", color="gray", fontsize=9)
            ax.set_xlim(0, 5)
            ax.set_ylim(0, 1.05)
            ax.axis('off')
        else:
            ax.plot(perf_df["Chunk"], perf_df["Recall"], marker='o', linestyle='-', markersize=4,
                    label='Recall', color='#007bff', zorder=2)
            ax.axhline(y=recall_lcl, color='#6495ED', linestyle='--', linewidth=1.5,
                       label=f'LCL ({recall_lcl:.2%})', zorder=1)
            below_lcl_points = perf_df[perf_df['Recall'] < recall_lcl]
            if not below_lcl_points.empty:
                ax.scatter(below_lcl_points['Chunk'], below_lcl_points['Recall'],
                           color='red', s=40, zorder=3, label='LCL ë¯¸ë§Œ', marker='v')

            ax.set_xlabel("ì²­í¬ ë²ˆí˜¸ (n=200)", fontsize=9)
            ax.set_ylabel("ìž¬í˜„ìœ¨", fontsize=9)
            handles, labels = ax.get_legend_handles_labels()
            by_label = dict(zip(labels, handles))
            ax.legend(by_label.values(), by_label.keys(), fontsize=8)
            ax.grid(True, alpha=0.3, linestyle=':')
            ax.set_ylim(-0.05, 1.05)
            min_x, max_x = perf_df["Chunk"].min(), perf_df["Chunk"].max()
            x_margin = max(1, (max_x - min_x) * 0.05)
            ax.set_xlim(max(0, min_x - x_margin), max_x + x_margin)
            ax.tick_params(axis='both', which='major', labelsize=8)

        plt.tight_layout(pad=0.5)
        return fig

    @output
    @render.plot(alt="Real-time Precision Trend Plot")
    def realtime_precision_plot():
        perf_df = realtime_performance()
        fig, ax = plt.subplots()
        if perf_df.empty:
            ax.text(0.5, 0.5, "ë°ì´í„° ìˆ˜ì§‘ ì¤‘...", ha="center", va="center", color="gray", fontsize=9)
            ax.set_xlim(0, 5)
            ax.set_ylim(0, 1.05)
            ax.axis('off')
        else:
            ax.plot(perf_df["Chunk"], perf_df["Precision"], marker='s', linestyle='-', markersize=4,
                    label='Precision', color='#28a745', zorder=2)
            ax.axhline(y=precision_lcl, color='#3CB371', linestyle='--', linewidth=1.5,
                       label=f'LCL ({precision_lcl:.2%})', zorder=1)
            below_lcl_points = perf_df[perf_df['Precision'] < precision_lcl]
            if not below_lcl_points.empty:
                ax.scatter(below_lcl_points['Chunk'], below_lcl_points['Precision'],
                           color='red', s=40, zorder=3, label='LCL ë¯¸ë§Œ', marker='v')

            ax.set_xlabel("ì²­í¬ ë²ˆí˜¸ (n=200)", fontsize=9)
            ax.set_ylabel("ì •ë°€ë„", fontsize=9)
            handles, labels = ax.get_legend_handles_labels()
            by_label = dict(zip(labels, handles))
            ax.legend(by_label.values(), by_label.keys(), fontsize=8)
            ax.grid(True, alpha=0.3, linestyle=':')
            ax.set_ylim(-0.05, 1.05)
            min_x, max_x = perf_df["Chunk"].min(), perf_df["Chunk"].max()
            x_margin = max(1, (max_x - min_x) * 0.05)
            ax.set_xlim(max(0, min_x - x_margin), max_x + x_margin)
            ax.tick_params(axis='both', which='major', labelsize=8)

        plt.tight_layout(pad=0.5)
        return fig

    def create_tooltip_ui(hover_info, perf_data, lcl_value, metric_name):
        if not hover_info or perf_data.empty:
            return None
        x_hover = hover_info['x']
        if perf_data.empty:
            return None

        distances = (perf_data['Chunk'] - x_hover).abs()
        if distances.empty:
            return None

        try:
            nearest_chunk_idx = distances.idxmin()
            point = perf_data.loc[nearest_chunk_idx]

            if abs(point['Chunk'] - x_hover) > 0.5:
                return None

            if point[metric_name] < lcl_value:
                cm_html = f"""
                <table style='margin: 0;'>
                    <tr><th colspan='2' style='font-size: 0.85rem; padding: 3px 6px;'>Chunk {int(point['Chunk'])}</th></tr>
                    <tr><td style='padding: 3px 6px;'>TP: {int(point['TP'])}</td><td style='padding: 3px 6px;'>FP: {int(point['FP'])}</td></tr>
                    <tr><td style='padding: 3px 6px;'>FN: {int(point['FN'])}</td><td style='padding: 3px 6px;'>TN: {int(point['TN'])}</td></tr>
                </table>
                <div style='font-size: 0.8rem; text-align: center; margin-top: 3px;'>
                    {metric_name}: {point[metric_name]:.2%} (LCL: {lcl_value:.2%})
                </div>
                """
                left = hover_info['coords_css']['x'] + 10
                top = hover_info['coords_css']['y'] + 10
                return ui.div(ui.HTML(cm_html), class_="plot-tooltip",
                                style=f"left: {left}px; top: {top}px; border: 1px solid red;")
        except KeyError:
            return None
        return None

    @reactive.effect
    def _():
        recall_tooltip.set(create_tooltip_ui(
            input.realtime_recall_plot_hover(), realtime_performance(), recall_lcl, 'Recall'
        ))

    @output
    @render.ui
    def recall_tooltip_ui():
        return recall_tooltip.get()

    @reactive.effect
    def _():
        precision_tooltip.set(create_tooltip_ui(
            input.realtime_precision_plot_hover(), realtime_performance(), precision_lcl, 'Precision'
        ))

    @output
    @render.ui
    def precision_tooltip_ui():
        return precision_tooltip.get()

    # ===================== ì±—ë´‡ =====================
    @output
    @render.ui
    def chatbot_popup():
        if not chatbot_visible.get():
            return None
    
        return ui.div(
            ui.div(
                style=(
                    "position: fixed; top: 0; left: 0; width: 100%; height: 100%; "
                    "background-color: rgba(0, 0, 0, 0.5); z-index: 1050;"
                )
            ),
            ui.div(
                ui.div("ðŸ¤– AI ì±—ë´‡", class_="fw-bold mb-2", style="font-size: 22px; text-align:center;"),
                ui.div(
                    ui.output_ui("chatbot_response"),
                    style=(
                        "height: 600px; overflow-y: auto; border: 1px solid #ddd; border-radius: 10px; "
                        "padding: 15px; background-color: #f0f4f8; margin-bottom: 12px; font-size: 14px; line-height: 1.4;"
                    )
                ),
                ui.div(
                    ui.input_text("chat_input", "", placeholder="ë©”ì‹œì§€ë¥¼ ìž…ë ¥í•˜ì„¸ìš”...", width="80%"),
                    ui.input_action_button("send_chat", "ì „ì†¡", class_="btn btn-primary", style="width: 18%; margin-left: 2%;"),
                    style="display: flex; align-items: center;"
                ),
                ui.input_action_button("close_chatbot", "ë‹«ê¸° âœ–", class_="btn btn-secondary mt-3 w-100"),
                style=(
                    "position: fixed; bottom: 90px; right: 20px; width: 800px; background-color: white; "
                    "border-radius: 15px; box-shadow: 0 6px 20px rgba(0, 0, 0, 0.25); "
                    "z-index: 1100; padding: 20px; font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;"
                )
            )
        )  
    
    @reactive.effect
    @reactive.event(input.toggle_chatbot)
    def _():
        chatbot_visible.set(not chatbot_visible.get())
    
    @reactive.Effect
    @reactive.event(input.close_chatbot)
    def _():
        chatbot_visible.set(False)
      
    @reactive.Effect
    @reactive.event(input.send_chat)
    async def handle_chat_send():
        query = input.chat_input().strip()
        if not query:
            ui.notification_show("ì§ˆë¬¸ì„ ìž…ë ¥í•´ì£¼ì„¸ìš”.", duration=3, type="warning")
            return
        
        ui.update_text("chat_input", value="")
        process_chat_query(query)

    def process_chat_query(query: str):
        if not API_KEY:
            r_ai_answer.set("âŒ Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ì±—ë´‡ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        r_is_loading.set(True)
        r_ai_answer.set("")

        df = current_data()
        if df.empty:
            r_ai_answer.set("â— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ìŠ¤íŠ¸ë¦¬ë°ì„ ì‹œìž‘í•´ì£¼ì„¸ìš”.")
            r_is_loading.set(False)
            return

        dashboard_summary = get_dashboard_summary(df)
        df_filtered, analyze_type = filter_df_by_question(df, query)

        if df_filtered.empty and analyze_type != "No Match":
            r_ai_answer.set(f"â— '{analyze_type}'ì— ëŒ€í•œ ë°ì´í„°ëŠ” ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            r_is_loading.set(False)
            return

        date_range_info = dashboard_summary.get("ìµœì‹ _ì‹œê°„", "N/A")
        defect_count_info = "ë¶ˆëŸ‰ ì˜ˆì¸¡ ê²°ê³¼ ì—†ìŒ"
        if not df_filtered.empty and 'defect_status' in df_filtered.columns:
            label_counts = df_filtered['defect_status'].value_counts()
            defect_count = label_counts.get(1, 0)
            good_count = label_counts.get(0, 0)
            total_count_filtered = label_counts.sum()
            defect_rate_filtered = (defect_count / total_count_filtered) * 100 if total_count_filtered > 0 else 0
            defect_count_info = f"í•„í„°ë§ëœ {total_count_filtered}ê±´ ë¶„ì„ ì¤‘ (ë¶ˆëŸ‰: {defect_count}ê±´, ì–‘í’ˆ: {good_count}ê±´, ë¶ˆëŸ‰ë¥ : {defect_rate_filtered:.2f}%)"
            
            if 'registration_time' in df_filtered.columns:
                try:
                    min_date = df_filtered['registration_time'].min().strftime('%Y-%m-%d %H:%M')
                    max_date = df_filtered['registration_time'].max().strftime('%Y-%m-%d %H:%M')
                    date_range_info = f"ê¸°ê°„: {min_date} ~ {max_date}"
                except Exception:
                    date_range_info = "ê¸°ê°„ ì •ë³´ ì˜¤ë¥˜"

        latest_defect_id_info = "ë¶ˆëŸ‰ ì œí’ˆ ID ì •ë³´ ì—†ìŒ."
        defect_log_df = defect_logs.get()
        if not defect_log_df.empty and 'ID' in defect_log_df.columns:
            latest_ids_raw = defect_log_df['ID'].tail(20).tolist()
            latest_ids = list(map(str, latest_ids_raw))
            latest_defect_id_info = f"ìµœê·¼ ë¶ˆëŸ‰ ì œí’ˆ 20ê±´ì˜ ID: {', '.join(latest_ids)}"

        summary_text = generate_summary_for_gemini(dashboard_summary, query)
        prompt = f"""
        ë‹¹ì‹ ì€ ê³µì • ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œì˜ AI ì±—ë´‡ìž…ë‹ˆë‹¤.
        ì•„ëž˜ [ëŒ€ì‹œë³´ë“œ í•µì‹¬ ì •ë³´]ì™€ [ë°ì´í„° ë¶„ì„ ê²°ê³¼]ë¥¼ ì°¸ê³ í•˜ì—¬, ì‚¬ìš©ìžì˜ ì§ˆë¬¸ì— ëŒ€í•´ ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ ì£¼ì„¸ìš”. ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ìž‘ì„±í•´ì£¼ì„¸ìš”.

        ---
        **[ëŒ€ì‹œë³´ë“œ í•µì‹¬ ì •ë³´ (íƒ­ 1 & 3)]**
        {summary_text}
        
        **[ë°ì´í„° ë¶„ì„ ê²°ê³¼ (ì§ˆë¬¸ ê¸°ë°˜ í•„í„°ë§)]**
        - ë¶„ì„ ëŒ€ìƒ: {analyze_type}
        - ë¶„ì„ ëŒ€ìƒ ê¸°ê°„/ì‹œì : {date_range_info}
        - {defect_count_info}
        - {latest_defect_id_info}

        ---
        ì‚¬ìš©ìžì˜ ì§ˆë¬¸: "{query}"

        **ë‹µë³€ ê°€ì´ë“œ:**
        1. ì§ˆë¬¸ì˜ í•µì‹¬ í‚¤ì›Œë“œë¥¼ íŒŒì•…í•˜ì„¸ìš”.
        2. ì§ˆë¬¸ì— í•´ë‹¹í•˜ëŠ” ì •ë³´ê°€ [ëŒ€ì‹œë³´ë“œ í•µì‹¬ ì •ë³´]ì— ìžˆë‹¤ë©´, í•´ë‹¹ ì •ë³´ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.
        3. ì§ˆë¬¸ì´ íŠ¹ì • ê¸°ê°„ì´ë‚˜ ê±´ìˆ˜ë¥¼ ëª…ì‹œí–ˆë‹¤ë©´, [ë°ì´í„° ë¶„ì„ ê²°ê³¼]ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì‚¬ìš©í•˜ì„¸ìš”.
        4. ìˆ˜ì¹˜ì—ëŠ” ë‹¨ìœ„ë¥¼ ëª…í™•ížˆ í‘œì‹œí•˜ê³ , ì¤‘ìš”í•œ ì •ë³´ëŠ” **êµµê²Œ** í‘œì‹œí•´ ì£¼ì„¸ìš”.
        5. ë‹µë³€ì€ ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ í†¤ì„ ìœ ì§€í•˜ì„¸ìš”.
        """
        
        try:
            model = genai.GenerativeModel(GEMINI_MODEL_NAME)
            # âœ… íƒ€ìž„ì•„ì›ƒì„ í¬í•¨í•œ ë™ê¸°ì‹ í˜¸ì¶œ (30ì´ˆ)
            import threading
            result = {"text": None, "error": None}
            
            def api_call():
                try:
                    response = model.generate_content(prompt)
                    result["text"] = response.text.strip()
                except Exception as e:
                    result["error"] = str(e)
            
            thread = threading.Thread(target=api_call, daemon=True)
            thread.start()
            thread.join(timeout=30)  # 30ì´ˆ íƒ€ìž„ì•„ì›ƒ
            
            if result["text"]:
                r_ai_answer.set(result["text"])
            elif result["error"]:
                error_msg = result["error"]
                if "API_KEY" in error_msg or "401" in error_msg:
                    r_ai_answer.set("âŒ Gemini API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. í™˜ê²½ ë³€ìˆ˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
                else:
                    r_ai_answer.set(f"âŒ AI ì‘ë‹µ ì˜¤ë¥˜: {error_msg}")
            else:
                r_ai_answer.set("âŒ AI ì‘ë‹µ íƒ€ìž„ì•„ì›ƒ (30ì´ˆ ì´ˆê³¼). ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                
        except Exception as e:
            r_ai_answer.set(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}")
            print(f"ERROR: {e}")
        
        finally:
            # âœ… í•­ìƒ ë¡œë”© ìƒíƒœ í•´ì œ
            r_is_loading.set(False)

    @output
    @render.ui
    def chatbot_response():
        if r_is_loading.get():
            return ui.div(
                 ui.div({"class": "spinner-border text-primary", "role": "status"}, 
                        ui.span({"class": "visually-hidden"}, "Loading...")),
                 ui.p("AIê°€ ë‹µë³€ì„ ìƒì„± ì¤‘ìž…ë‹ˆë‹¤...", style="margin-left: 10px; color: #555;"),
                 style="display: flex; align-items: center; justify-content: center; height: 100%;"
            )

        return ui.markdown(r_ai_answer.get())

    def filter_df_by_question(df, query):
        df_filtered = pd.DataFrame()
        analyze_type = "No Match" 

        if 'registration_time' in df.columns:
            if not pd.api.types.is_datetime64_any_dtype(df['registration_time']):
                try:
                    df = df.copy()
                    df['registration_time'] = pd.to_datetime(df['registration_time'], errors='coerce')
                    df = df.dropna(subset=['registration_time'])
                except Exception as e:
                    print(f"ì‹œê°„ ë°ì´í„° ë³€í™˜ ì˜¤ë¥˜: {e}")
                    return pd.DataFrame(), "ì‹œê°„ ë°ì´í„° ë³€í™˜ ì˜¤ë¥˜"
        else:
             return pd.DataFrame(), "ì‹œê°„ ì»¬ëŸ¼('registration_time') ì—†ìŒ"

        today = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)

        count_pattern = re.compile(r'(?:ìµœê·¼|ê°€ìž¥ ìµœê·¼)\s*(\d+)\s*(?:ê°œ|ê±´)')
        count_match = count_pattern.search(query)

        if count_match:
            count = int(count_match.group(1))
            df_sorted = df.sort_values('registration_time')
            df_filtered = df_sorted.tail(count).copy()
            analyze_type = f"í•„í„°ë§ëœ ê±´ìˆ˜: ìµœê·¼ {len(df_filtered)}ê±´"
            return df_filtered, analyze_type

        start_date, end_date = None, None
        query_lower = query.lower().replace(" ", "")

        if 'ì˜¤ëŠ˜' in query_lower or 'ë‹¹ì¼' in query_lower:
            start_date = today
            end_date = today + timedelta(days=1)
            analyze_type = "í•„í„°ë§ëœ ê¸°ê°„: ì˜¤ëŠ˜"
        elif 'ì–´ì œ' in query_lower or 'ì „ì¼' in query_lower:
            start_date = today - timedelta(days=1)
            end_date = today
            analyze_type = "í•„í„°ë§ëœ ê¸°ê°„: ì–´ì œ"
        elif 'ì´ë²ˆì£¼' in query_lower or 'ê¸ˆì£¼' in query_lower:
            start_date = today - timedelta(days=today.weekday())
            end_date = start_date + timedelta(weeks=1)
            analyze_type = "í•„í„°ë§ëœ ê¸°ê°„: ì´ë²ˆ ì£¼"
        elif 'ì§€ë‚œì£¼' in query_lower or 'ì „ì£¼' in query_lower:
            start_of_this_week = today - timedelta(days=today.weekday())
            start_date = start_of_this_week - timedelta(weeks=1)
            end_date = start_of_this_week
            analyze_type = "í•„í„°ë§ëœ ê¸°ê°„: ì§€ë‚œ ì£¼"

        if start_date is not None:
            df_sorted = df.sort_values('registration_time')
            df_filtered = df_sorted[
                (df_sorted['registration_time'] >= start_date) &
                (df_sorted['registration_time'] < end_date)
            ].copy()

            if df_filtered.empty:
                return pd.DataFrame(), f"{analyze_type} (ë°ì´í„° ì—†ìŒ)"

            return df_filtered, f"{analyze_type} (ì´ {len(df_filtered)}ê±´)"
        
        return pd.DataFrame(), "No Match"

    def get_dashboard_summary(current_data_df: pd.DataFrame):
        status_text = "ðŸŸ¢ ê³µì • ì§„í–‰ ì¤‘"
        if was_reset():
            status_text = "ðŸŸ¡ ë¦¬ì…‹ë¨"
        elif not is_streaming():
            status_text = "ðŸ”´ ì¼ì‹œ ì •ì§€ë¨"

        anomaly_label = {0: "ì–‘í˜¸", 1: "ê²½ê³ "}.get(latest_anomaly_status(), "N/A")
        defect_label = {0: "ì–‘í’ˆ", 1: "ë¶ˆëŸ‰"}.get(latest_defect_status(), "N/A")
        
        latest_time_str = "ë°ì´í„° ì—†ìŒ"
        if not current_data_df.empty and "registration_time" in current_data_df.columns:
             latest_time = pd.to_datetime(current_data_df["registration_time"], errors='coerce').max()
             if not pd.isna(latest_time):
                 latest_time_str = latest_time.strftime("%Y-%m-%d %H:%M:%S")

        stats = get_realtime_stats(current_data_df)
        total_count = stats.get("total", 0)
        anomaly_rate = stats.get("anomaly_rate", 0.0)
        anomaly_count = stats.get("anomaly_count", 0)
        defect_rate = stats.get("defect_rate", 0.0)
        today_defect_rate = stats.get("today_defect_rate", 0.0)
        accuracy = stats.get("defect_accuracy", 0.0)
        goal_progress = stats.get("goal_progress", 0.0)
        goal_target = stats.get("goal_target", 'N/A')

        cum_perf = cumulative_performance()
        cum_recall = f"{cum_perf['recall'] * 100:.2f}%"
        cum_precision = f"{cum_perf['precision'] * 100:.2f}%"
    
        latest_perf = latest_performance_metrics()
        latest_recall = f"{latest_perf['recall'] * 100:.2f}%"
        latest_precision = f"{latest_perf['precision'] * 100:.2f}%"

        perf_status = performance_degradation_status()
        perf_status_text = "ðŸš¨ ì„±ëŠ¥ ì €í•˜ ê°ì§€" if perf_status["degraded"] else "âœ… ì„±ëŠ¥ ì–‘í˜¸"

        drift_stat = data_drift_status()
        drift_status_text = f"ðŸš¨ ë“œë¦¬í”„íŠ¸ ì˜ì‹¬ ({drift_stat.get('feature', 'N/A')})" if drift_stat["degraded"] else "âœ… ë¶„í¬ ì–‘í˜¸"
        
        defect_log_count = len(defect_logs())
        feedback_count = len(r_feedback_data())

        summary = {
            "ê³µì •_ìƒíƒœ": status_text, "ìµœì‹ _ì‹œê°„": latest_time_str,
            "ìµœê·¼_ì´ìƒì¹˜_ìƒíƒœ": anomaly_label, "ìµœê·¼_ë¶ˆëŸ‰_ìƒíƒœ": defect_label,
            "ì´_ì²˜ë¦¬_ê±´ìˆ˜": total_count, 
            "ì´ìƒì¹˜_íƒì§€ìœ¨": f"{anomaly_rate:.2f}%",
            "ì´ìƒì¹˜_íƒì§€_ê±´ìˆ˜": anomaly_count,
            "ë¶ˆëŸ‰_íƒì§€ìœ¨_ì „ì²´": f"{defect_rate:.2f}%", "ì˜¤ëŠ˜_ë¶ˆëŸ‰ë¥ ": f"{today_defect_rate:.2f}%",
            "ëª¨ë¸_ì˜ˆì¸¡_ì •í™•ë„": f"{accuracy:.2f}%",
            "ëª©í‘œ_ë‹¬ì„±ë¥ ": f"{goal_progress:.2f}% (ëª©í‘œ: {goal_target}ê°œ)",
            "ëˆ„ì _ìž¬í˜„ìœ¨": cum_recall, "ëˆ„ì _ì •ë°€ë„": cum_precision,
            "ìµœê·¼_ì²­í¬_ìž¬í˜„ìœ¨": latest_recall, "ìµœê·¼_ì²­í¬_ì •ë°€ë„": latest_precision,
            "ëª¨ë¸_ì„±ëŠ¥_ìƒíƒœ": perf_status_text,
            "ë°ì´í„°_ë¶„í¬_ìƒíƒœ": drift_status_text,
            "ë¶ˆëŸ‰_ë¡œê·¸_ê±´ìˆ˜": defect_log_count, "í”¼ë“œë°±_ì´_ê±´ìˆ˜": feedback_count,
        }
        return summary

    KEYWORD_TO_INFO = {
        "ìƒíƒœ": ["ê³µì •_ìƒíƒœ", "ì´_ì²˜ë¦¬_ê±´ìˆ˜", "ìµœì‹ _ì‹œê°„"],
        "í˜„ìž¬": ["ê³µì •_ìƒíƒœ", "ë¶ˆëŸ‰_íƒì§€ìœ¨_ì „ì²´", "ìµœì‹ _ì‹œê°„", "ì˜¤ëŠ˜_ë¶ˆëŸ‰ë¥ "],
        "ì§€ê¸ˆ": ["ê³µì •_ìƒíƒœ", "ìµœì‹ _ì‹œê°„"],
        "ì˜¤ëŠ˜": ["ì˜¤ëŠ˜_ë¶ˆëŸ‰ë¥ ", "ì´_ì²˜ë¦¬_ê±´ìˆ˜"],
        "ë©ˆì·„": ["ê³µì •_ìƒíƒœ"], "ë¦¬ì…‹": ["ê³µì •_ìƒíƒœ"],
        "ì´ìƒì¹˜": ["ìµœê·¼_ì´ìƒì¹˜_ìƒíƒœ", "ì´ìƒì¹˜_íƒì§€ìœ¨", "ì´ìƒì¹˜_íƒì§€_ê±´ìˆ˜"],
        "ë¶ˆëŸ‰": ["ìµœê·¼_ë¶ˆëŸ‰_ìƒíƒœ", "ë¶ˆëŸ‰_íƒì§€ìœ¨_ì „ì²´", "ì˜¤ëŠ˜_ë¶ˆëŸ‰ë¥ ", "ë¶ˆëŸ‰_ë¡œê·¸_ê±´ìˆ˜"],
        "ë¶ˆëŸ‰ë¥ ": ["ë¶ˆëŸ‰_íƒì§€ìœ¨_ì „ì²´", "ì˜¤ëŠ˜_ë¶ˆëŸ‰ë¥ "],
        "ì •í™•ë„": ["ëª¨ë¸_ì˜ˆì¸¡_ì •í™•ë„"],
        "ìž¬í˜„ìœ¨": ["ëˆ„ì _ìž¬í˜„ìœ¨", "ìµœê·¼_ì²­í¬_ìž¬í˜„ìœ¨"],
        "ì •ë°€ë„": ["ëˆ„ì _ì •ë°€ë„", "ìµœê·¼_ì²­í¬_ì •ë°€ë„"],
        "ì„±ëŠ¥": ["ëª¨ë¸_ì„±ëŠ¥_ìƒíƒœ", "ëˆ„ì _ìž¬í˜„ìœ¨", "ëˆ„ì _ì •ë°€ë„"],
        "ë“œë¦¬í”„íŠ¸": ["ë°ì´í„°_ë¶„í¬_ìƒíƒœ"],
        "ë¶„í¬": ["ë°ì´í„°_ë¶„í¬_ìƒíƒœ"],
        "ëª©í‘œ": ["ëª©í‘œ_ë‹¬ì„±ë¥ "],
        "í”¼ë“œë°±": ["í”¼ë“œë°±_ì´_ê±´ìˆ˜"],
        "ì´": ["ì´_ì²˜ë¦¬_ê±´ìˆ˜"], "ìµœì‹ ": ["ìµœì‹ _ì‹œê°„"],
    }

    def generate_summary_for_gemini(summary, query):
        query_lower = query.lower().replace(" ", "")
        required_keys = set()
        for keyword, keys in KEYWORD_TO_INFO.items():
            if keyword in query_lower:
                required_keys.update(keys)

        if not required_keys or any(k in query_lower for k in ["ì „ì²´", "ìš”ì•½", "ëª¨ë“ ", "í˜„í™©", "ì•Œë ¤ì¤˜"]):
            required_keys = {
                "ê³µì •_ìƒíƒœ", "ì´_ì²˜ë¦¬_ê±´ìˆ˜", "ì´ìƒì¹˜_íƒì§€ìœ¨", "ì´ìƒì¹˜_íƒì§€_ê±´ìˆ˜",
                "ë¶ˆëŸ‰_íƒì§€ìœ¨_ì „ì²´", "ëª¨ë¸_ì˜ˆì¸¡_ì •í™•ë„",
                "ëˆ„ì _ìž¬í˜„ìœ¨", "ëˆ„ì _ì •ë°€ë„", "ëª¨ë¸_ì„±ëŠ¥_ìƒíƒœ", "ë°ì´í„°_ë¶„í¬_ìƒíƒœ"
            }

        info_parts = []
        base_keys = ["ê³µì •_ìƒíƒœ", "ì´_ì²˜ë¦¬_ê±´ìˆ˜", "ìµœì‹ _ì‹œê°„"]
        for key in base_keys:
             if key in summary:
                 info_parts.append(f"[{key.replace('_', ' ')}]: {summary[key]}")
        
        for key, value in summary.items():
            if key in required_keys and key not in base_keys:
                info_parts.append(f"[{key.replace('_', ' ')}]: {value}")

        return "\n".join(info_parts)

# ==================== APP ì‹¤í–‰ ====================
app = App(app_ui, server)






