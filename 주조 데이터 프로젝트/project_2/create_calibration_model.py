import pandas as pd
import numpy as np
import joblib
from pathlib import Path
from sklearn.neighbors import NearestNeighbors
from sklearn.isotonic import IsotonicRegression
from sklearn.impute import SimpleImputer
from collections import defaultdict
import warnings

warnings.filterwarnings("ignore")

print("--- Isotonic Î≥¥Ï†ï Î™®Îç∏ ÏÉùÏÑ± ÏãúÏûë ---")
print("shared.pyÏóêÏÑú ÌïÑÏöî Î™®Îìà Î°úÎìú Ï§ë...")

try:
    # 1. shared.pyÏóêÏÑú 'ÏßÑÏßú' Í≥µÏú† ÏûêÏõêÎßå Î°úÎìúÌï©ÎãàÎã§.
    from shared import (
        train_df, test_df, predict_anomaly,
        anomaly_transform, ANOM_FEATURE_ORDER, feature_cols,
        ANOM_PREPROCESSOR, get_preproc_feature_names_out
    )
    print("‚úÖ shared.py Î™®Îìà Î°úÎìú ÏÑ±Í≥µ")
except ImportError as e:
    print(f"‚ùå shared.py Î°úÎìú Ïã§Ìå®: {e}")
    exit()
except Exception as e:
    print(f"‚ùå shared.py Ïã§Ìñâ Ï§ë Ïò§Î•ò (Îç∞Ïù¥ÌÑ∞ Î°úÎìú Îì±): {e}")
    exit()

print("app.pyÏùò Î≥¥Ï†ï Î°úÏßÅÏùÑ Î≥µÏ†úÌïòÏó¨ Ïã§ÌñâÌï©ÎãàÎã§...")

try:
    # 2. app.pyÏùò Ìó¨Ìçº Î≥ÄÏàò Î∞è Ìï®Ïàò Ï†ïÏùòÎ•º 'Î≥µÏÇ¨' (app.py ÏõêÎ≥∏ 182-227Ìñâ)
    
    # üî¥ [Î≥µÏÇ¨ 1] INPUT_FEATURES (app.py 182Ìñâ)
    INPUT_FEATURES = ANOM_FEATURE_ORDER if len(ANOM_FEATURE_ORDER) else feature_cols

    # üî¥ [Î≥µÏÇ¨ 2] PREPROC_FEATURES (app.py 185-188Ìñâ)
    try:
        PREPROC_FEATURES = list(get_preproc_feature_names_out())
    except Exception:
        PREPROC_FEATURES = [f"feat_{i}" for i in range(anomaly_transform(train_df[INPUT_FEATURES]).shape[1])]

    # üî¥ [Î≥µÏÇ¨ 3] _base_from_preproc_name (app.py 190-194Ìñâ)
    def _base_from_preproc_name(name: str) -> str:
        n = str(name).split("__")[-1]
        if "=" in n:
            return n.split("=")[0]
        cand = n.rsplit("_", 1)[0]
        return cand if cand in INPUT_FEATURES else n

    # üî¥ [Î≥µÏÇ¨ 4] _GROUP_IDX, _PREPROC_BASES (app.py 195-201Ìñâ)
    _GROUP_IDX = defaultdict(list)
    _PREPROC_BASES = []
    for j, pname in enumerate(PREPROC_FEATURES):
        base = _base_from_preproc_name(pname)
        if base == pname and pname.startswith("feat_"):
            if j < len(INPUT_FEATURES):
                base = INPUT_FEATURES[j]
        _PREPROC_BASES.append(base)
        _GROUP_IDX[base].append(j)

    # üî¥ [Î≥µÏÇ¨ 5] _NUM_IMPUTE_STATS (app.py 200-215Ìñâ)
    _NUM_IMPUTE_STATS = {}
    try:
        if hasattr(ANOM_PREPROCESSOR, "transformers_"):
            for _, trans, cols in ANOM_PREPROCESSOR.transformers_:
                if hasattr(trans, "named_steps") and "imputer" in trans.named_steps:
                    imp = trans.named_steps["imputer"]
                    if isinstance(imp, SimpleImputer) and hasattr(imp, "statistics_"):
                        for c, v in zip(cols, imp.statistics_):
                            _NUM_IMPUTE_STATS[c] = v
                elif isinstance(trans, SimpleImputer) and hasattr(trans, "statistics_"):
                    for c, v in zip(cols, trans.statistics_):
                        _NUM_IMPUTE_STATS[c] = v
    except Exception:
        pass

    # üî¥ [Î≥µÏÇ¨ 6] _imputed_raw (app.py 217-221Ìñâ)
    def _imputed_raw(row: pd.Series, base: str):
        v = row.get(base, np.nan)
        if pd.isna(v) and base in _NUM_IMPUTE_STATS:
            return _NUM_IMPUTE_STATS[base]
        return v

    # üî¥ [Î≥µÏÇ¨ 7] Ï∞∏Ï°∞ ÌñâÎ†¨ Î∞è NN Î™®Îç∏ (app.py 224-227Ìñâ)
    _Z_ref = anomaly_transform(train_df[INPUT_FEATURES])
    CAL_K = 80    # app.pyÏùò 176Ìñâ
    _nn_model = NearestNeighbors(n_neighbors=min(CAL_K, len(_Z_ref)), metric="euclidean")
    _nn_model.fit(_Z_ref)
    
    _RIDGE = 1e-6 # app.pyÏùò 178Ìñâ

    # üî¥ [Î≥µÏÇ¨ 8] _xi_from_row (app.py 229-232Ìñâ)
    def _xi_from_row(row: pd.Series) -> np.ndarray:
        X1 = pd.DataFrame([row]).reindex(columns=INPUT_FEATURES)
        Zi = anomaly_transform(X1)[0]
        return Zi

    # üî¥ [Î≥µÏÇ¨ 9] _local_mahalanobis_parts (app.py 234-243Ìñâ)
    def _local_mahalanobis_parts(xi: np.ndarray):
        _, idx = _nn_model.kneighbors([xi], n_neighbors=min(CAL_K, len(_Z_ref)))
        neigh = _Z_ref[idx[0]]
        mu = neigh.mean(axis=0)
        Sigma = np.cov(neigh, rowvar=False)
        Sigma = Sigma + np.eye(Sigma.shape[0]) * _RIDGE
        invS = np.linalg.pinv(Sigma)
        diff = xi - mu
        parts = diff * (invS @ diff)
        D2 = float(diff @ invS @ diff)
        return parts, D2, mu

    # üî¥ [Î≥µÏÇ¨ 10] _effective_anom_proba (app.py 245-253Ìñâ, Ïù¥Ï†Ñ Îã®Í≥ÑÏóêÏÑú Ï∂îÍ∞ÄÌï®)
    def _effective_anom_proba(ana_res: pd.DataFrame):
        aprob_raw = float(ana_res.get("anom_proba", [np.nan])[0]) if "anom_proba" in ana_res.columns else np.nan
        strength = float(ana_res.get("prob", [np.nan])[0]) if "prob" in ana_res.columns else np.nan
        if (not np.isfinite(aprob_raw)) or (aprob_raw <= 0):
            aprob_eff = 1.0 - (strength if np.isfinite(strength) else 0.0)
        else:
            aprob_eff = aprob_raw
        return aprob_eff, strength

    # 3. app.pyÏùò _collect_calibration_pairs Ìï®Ïàò 'Î≥µÏÇ¨' (app.py ÏõêÎ≥∏ 230-252Ìñâ)
    _MAX_CAL_SAMPLES = 500 # app.pyÏùò 177Ìñâ
    
    def _collect_calibration_pairs(max_samples=_MAX_CAL_SAMPLES):
        print(f"\nÎ≥¥Ï†ïÏö© ÏÉòÌîå ÏàòÏßë ÏãúÏûë (max_samples={max_samples})...")
        if len(test_df) == 0:
            return None, None
        idxs_eq = np.linspace(0, len(test_df)-1, num=min(max_samples, len(test_df)), dtype=int)
        idxs_rd = np.random.RandomState(42).choice(len(test_df), size=min(max_samples//2, len(test_df)), replace=False)
        idxs = np.unique(np.concatenate([idxs_eq, idxs_rd]))
        
        d2_list, p_list = [], []
        
        processed_count = 0
        for i in idxs:
            r = test_df.iloc[i]
            try:
                xi = _xi_from_row(r)
                parts, D2, _ = _local_mahalanobis_parts(xi)
                # üî¥ Ïù¥ Î∂ÄÎ∂ÑÏù¥ Î∞îÎ°ú OOMÏùÑ Ïú†Î∞úÌïòÎäî Î¨¥Í±∞Ïö¥ Í≥ÑÏÇ∞ÏûÖÎãàÎã§.
                ana_res = predict_anomaly(pd.DataFrame([r])) 
                aprob_eff, _ = _effective_anom_proba(ana_res)
                
                if np.isfinite(D2) and np.isfinite(aprob_eff):
                    d2_list.append(D2)
                    p_list.append(aprob_eff)
                
                processed_count += 1
                if processed_count % 50 == 0:
                    print(f"  ... {processed_count}/{len(idxs)} ÏÉòÌîå Ï≤òÎ¶¨ Ï§ë ...")

            except Exception as e:
                # ‚ÑπÔ∏è Fallback Î°úÍ∑∏ Îì±Ïù¥ Ïó¨Í∏∞ÏÑú Ï∂úÎ†•Îê† Ïàò ÏûàÏäµÎãàÎã§ (Ï†ïÏÉÅ)
                print(f"  ‚ö†Ô∏è ÏÉòÌîå {i} Ï≤òÎ¶¨ Ï§ë Í≤ΩÍ≥† (Î¨¥Ïãú): {e}")
                continue
        
        if len(d2_list) < 20:
            print("‚ùå Ïú†Ìö®Ìïú (D2, P) ÏåçÏù¥ 20Í∞ú ÎØ∏ÎßåÏù¥Îùº Î≥¥Ï†ï Î™®Îç∏ ÏÉùÏÑ± Ïã§Ìå®.")
            return None, None
        
        print(f"‚úÖ Ï¥ù {len(d2_list)}Í∞úÏùò Ïú†Ìö®Ìïú Î≥¥Ï†ï ÏÉòÌîå ÏàòÏßë ÏôÑÎ£å.")
        d2 = np.asarray(d2_list)
        p = np.asarray(p_list)
        order = np.argsort(d2)
        return d2[order], p[order]

    # 4. Í≥ÑÏÇ∞ Ïã§Ìñâ Î∞è Ï†ÄÏû•
    _cal_d2, _cal_p = _collect_calibration_pairs()
    
    if _cal_d2 is not None:
        print("\nIsotonicRegression Î™®Îç∏ ÌîºÌåÖ Ï§ë...")
        _iso = IsotonicRegression(y_min=0.0, y_max=1.0, increasing=True, out_of_bounds="clip")
        _iso.fit(_cal_d2, _cal_p)
        _cal_bounds = (float(np.min(_cal_d2)), float(np.max(_cal_d2)))
        print("‚úÖ Î™®Îç∏ ÌîºÌåÖ ÏôÑÎ£å.")

        # 5. Í≤∞Í≥ºÎ¨º Ï†ÄÏû•
        app_dir = Path(__file__).parent
        output_path = app_dir / "data/calibration_model.pkl"
        joblib.dump({
            "iso_model": _iso,
            "cal_bounds": _cal_bounds
        }, output_path)
        
        print(f"\nüéâ ÏÑ±Í≥µ: Isotonic Î≥¥Ï†ï Î™®Îç∏Ïù¥ {output_path} Ïóê Ï†ÄÏû•ÎêòÏóàÏäµÎãàÎã§.")
        print("--- Ïù¥Ï†ú app.pyÎ•º ÏàòÏ†ïÌïòÍ≥† Ïï±ÏùÑ Î∞∞Ìè¨ÌïòÏÑ∏Ïöî. ---")
    else:
        print("\n‚ùå Ïã§Ìå®: Î≥¥Ï†ï Î™®Îç∏ÏùÑ ÏÉùÏÑ±ÌïòÏßÄ Î™ªÌñàÏäµÎãàÎã§.")

except Exception as e:
    print(f"\n‚ùå Ïä§ÌÅ¨Î¶ΩÌä∏ Ïã§Ìñâ Ï§ë ÏπòÎ™ÖÏ†Å Ïò§Î•ò Î∞úÏÉù: {e}")