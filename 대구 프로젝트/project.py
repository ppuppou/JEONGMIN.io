import pandas as pd
import numpy as np
import re
import plotly.express as px
import plotly.graph_objects as go
import requests
import time
import json
import os
from tqdm import tqdm

# ìœ„ë„ ê²½ë„ ì¶”ì¶œ
df = pd.read_csv('./ê²½ì°°ì„œ,ì§€êµ¬ëŒ€,íŒŒì¶œì†Œ,ì¹˜ì•ˆì„¼í„°,ì´ˆ.ì¤‘.ê³ .ëŒ€í•™êµ,ìœ í¥ì£¼ì .csv')

# ì—…ë¡œë“œëœ íŒŒì¼ ê²½ë¡œ
file_path = 'ê²½ì°°ì„œ,ì§€êµ¬ëŒ€,íŒŒì¶œì†Œ,ì¹˜ì•ˆì„¼í„°,ì´ˆ.ì¤‘.ê³ .ëŒ€í•™êµ,ìœ í¥ì£¼ì .csv'

# ì¹´ì¹´ì˜¤ API í‚¤ (ê°€ì¥ ì¤‘ìš”! ìƒˆë¡œ ë°œê¸‰ë°›ì€ í‚¤ë¥¼ ì •í™•íˆ ì…ë ¥í•´ì£¼ì„¸ìš”)
KAKAO_API_KEY = 'c6c8a4613ef4138eea36dbf1178a0d29'
API_URL = 'https://dapi.kakao.com/v2/local/search/address.json'

# --- 2. ê°œì„ ëœ ê¸°ëŠ¥ ---

# API í‚¤ê°€ ê¸°ë³¸ê°’ ê·¸ëŒ€ë¡œì¸ì§€ í™•ì¸
if 'YOUR_NEW_SECURE_API_KEY' in KAKAO_API_KEY:
    print("ğŸ›‘ [ì¤‘ìš”] ì¹´ì¹´ì˜¤ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì½”ë“œì˜ 'YOUR_NEW_SECURE_API_KEY' ë¶€ë¶„ì„ ì‹¤ì œ í‚¤ë¡œ ë³€ê²½í•´ì£¼ì„¸ìš”.")
    # í‚¤ê°€ ì—†ìœ¼ë©´ ì—¬ê¸°ì„œ ì‹¤í–‰ ì¤‘ë‹¨
else:
    try:
        # íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
        df = pd.read_csv('./ê²½ì°°ì„œ,ì§€êµ¬ëŒ€,íŒŒì¶œì†Œ,ì¹˜ì•ˆì„¼í„°,ì´ˆ.ì¤‘.ê³ .ëŒ€í•™êµ,ìœ í¥ì£¼ì .csv')
        print(f"âœ… íŒŒì¼ì„ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤. (ê²½ë¡œ: {file_path})")

        # ì£¼ì†Œë¥¼ ì¢Œí‘œë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
        def get_coords_from_address(address, api_key):
            if not isinstance(address, str) or not address.strip():
                return None, None, "ì£¼ì†Œ ì—†ìŒ"
            
            cleaned_address = re.sub(r'\s*\([^)]*\)', '', address).strip()
            headers = {'Authorization': f'KakaoAK {api_key}'}
            params = {'query': cleaned_address}
            
            try:
                response = requests.get(API_URL, headers=headers, params=params)
                if response.status_code == 401:
                    return None, None, "API í‚¤ ì¸ì¦ ì‹¤íŒ¨ (401)"
                response.raise_for_status()
                data = response.json()
                
                if data['documents']:
                    lon = data['documents'][0]['x']
                    lat = data['documents'][0]['y']
                    return lat, lon, "ì„±ê³µ"
                else:
                    return None, None, "ê²°ê³¼ ì—†ìŒ"
            except requests.exceptions.RequestException as e:
                return None, None, f"ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜: {e}"
            except Exception as e:
                return None, None, f"ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜: {e}"

        # --- 3. ì§€ì˜¤ì½”ë”© ì‹¤í–‰ ë° ìƒì„¸ ë¡œê·¸ ì¶œë ¥ ---
        
        print("\n--- ì§€ì˜¤ì½”ë”© ì‘ì—…ì„ ì‹œì‘í•©ë‹ˆë‹¤ ---")
        
        # ì„±ê³µ, ì‹¤íŒ¨ ì¹´ìš´í„° ì´ˆê¸°í™”
        success_count = 0
        fail_count = 0

        # ìœ„ë„ê°€ ë¹„ì–´ìˆëŠ” í–‰ë§Œ ëŒ€ìƒìœ¼ë¡œ ì‘ì—… ìˆ˜í–‰
        rows_to_process = df[df['ìœ„ë„'].isnull()].index
        if not rows_to_process.empty:
            for index in tqdm(rows_to_process, desc="ì§„í–‰ë¥ "):
                row = df.loc[index]
                lat, lon, status = None, None, "ì‹œì‘"

                # 1ì°¨: ë„ë¡œëª… ì£¼ì†Œ ì‹œë„
                if pd.notna(row['ë„ë¡œëª…']):
                    lat, lon, status = get_coords_from_address(row['ë„ë¡œëª…'], KAKAO_API_KEY)

                # 2ì°¨: ë„ë¡œëª… ì‹¤íŒ¨ ì‹œ ì§€ë²ˆ ì£¼ì†Œ ì‹œë„
                if not lat and pd.notna(row['ì§€ë²ˆ']):
                    jibun_address = f"ëŒ€êµ¬ê´‘ì—­ì‹œ {row['ì§€ë²ˆ']}"
                    lat, lon, status = get_coords_from_address(jibun_address, KAKAO_API_KEY)
                
                # ê²°ê³¼ì— ë”°ë¼ ì²˜ë¦¬ ë° ë¡œê·¸ ì¶œë ¥
                if lat and lon:
                    df.loc[index, 'ìœ„ë„'] = lat
                    df.loc[index, 'ê²½ë„'] = lon
                    success_count += 1
                    # print(f"  [ì„±ê³µ] index {index}: {row['ì´ë¦„']} -> {status}") # ë„ˆë¬´ ë§ì€ ë¡œê·¸ ëŒ€ì‹  ìµœì¢… ìš”ì•½ìœ¼ë¡œ ëŒ€ì²´
                else:
                    fail_count += 1
                    print(f"  [ì‹¤íŒ¨] index {index}: '{row['ì´ë¦„']}' / ì£¼ì†Œ: '{row['ë„ë¡œëª…']}' -> (ì›ì¸: {status})")

        # --- 4. ìµœì¢… ê²°ê³¼ ìš”ì•½ ë° ì €ì¥ ---
        
        print("\n--- ì‘ì—…ì´ ëª¨ë‘ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤ ---")
        print(f"ğŸ‰ ì´ {success_count + fail_count}ê±´ ì¤‘")
        print(f"  - ì„±ê³µ: {success_count}ê±´")
        print(f"  - ì‹¤íŒ¨: {fail_count}ê±´")

        # API í‚¤ ì¸ì¦ ì‹¤íŒ¨ê°€ í•œ ë²ˆì´ë¼ë„ ìˆì—ˆë‹¤ë©´ ì•ˆë‚´ ë©”ì‹œì§€ ì¶œë ¥
        if "API í‚¤ ì¸ì¦ ì‹¤íŒ¨" in locals().get('status', ''):
             print("\nâš ï¸ 'API í‚¤ ì¸ì¦ ì‹¤íŒ¨' ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì¹´ì¹´ì˜¤ ê°œë°œì ì‚¬ì´íŠ¸ì—ì„œ API í‚¤ê°€ ì •ìƒì ì¸ì§€, ì‚¬ìš© ê¶Œí•œì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")

        output_filename = 'geocoded_final_data_log.csv'
        df.to_csv(output_filename, index=False, encoding='utf-8-sig')
        print(f"\nâœ¨ ìµœì¢… ê²°ê³¼ê°€ '{output_filename}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    except FileNotFoundError:
        print(f"ğŸ›‘ [ì˜¤ë¥˜] íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìŠ¤í¬ë¦½íŠ¸ê°€ ìˆëŠ” í´ë”ì— '{file_path}' íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
    except Exception as e:
        print(f"ğŸ›‘ [ì˜¤ë¥˜] ì˜ˆìƒì¹˜ ëª»í•œ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")





# í–‰ì •ë™ ì¶”ê°€í•˜ëŠ” ì½”ë“œ

# --- 1. ì„¤ì • ë‹¨ê³„ ---
FILE_PATH = 'geocoded_final_data_log.csv' 
KAKAO_API_KEY = 'c6c8a4613ef4138eea36dbf1178a0d29' # ë³¸ì¸ì˜ ì¹´ì¹´ì˜¤ REST API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.
API_URL = 'https://dapi.kakao.com/v2/local/geo/coord2address.json'

# --- 2. ìˆ˜ì •ëœ ë¦¬ë²„ìŠ¤ ì§€ì˜¤ì½”ë”© í•¨ìˆ˜ ---
def get_dong_from_coords(latitude, longitude, api_key):
    """
    ì¢Œí‘œë¥¼ í–‰ì •ë™ìœ¼ë¡œ ë³€í™˜í•˜ë˜, í–‰ì •ë™ì´ ì—†ìœ¼ë©´ ë²•ì •ë™ì„ ëŒ€ì‹  ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
    """
    if pd.isna(latitude) or pd.isna(longitude):
        return None
        
    headers = {'Authorization': f'KakaoAK {api_key}'}
    params = {'x': longitude, 'y': latitude}
    
    try:
        response = requests.get(API_URL, headers=headers, params=params)
        response.raise_for_status()
        data = response.json()
        
        if data['documents']:
            # ì£¼ì†Œ ì •ë³´ë¥¼ ë³€ìˆ˜ì— ì €ì¥
            address_info = data['documents'][0]['address']
            
            # 1. í–‰ì •ë™(region_3depth_h_name)ì„ ìš°ì„ ì ìœ¼ë¡œ ê°€ì ¸ì˜¤ê¸°
            dong_name = address_info.get('region_3depth_h_name')
            
            # 2. ë§Œì•½ í–‰ì •ë™ ì •ë³´ê°€ ì—†ë‹¤ë©´, ëŒ€ì‹  ë²•ì •ë™(region_3depth_name)ì„ ê°€ì ¸ì˜¤ê¸°
            if not dong_name:
                dong_name = address_info.get('region_3depth_name')
                
            return dong_name
        else:
            return None
    except Exception:
        return None

# --- 3. ë°ì´í„° ì²˜ë¦¬ ë° ì‹¤í–‰ ---
try:
    df = pd.read_csv('./geocoded_final_data_log.csv')
    print(f"âœ… íŒŒì¼ì„ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤: {FILE_PATH}")

    if 'YOUR_NEW_SECURE_API_KEY' in KAKAO_API_KEY:
        print("ğŸ›‘ [ì¤‘ìš”] ì¹´ì¹´ì˜¤ API í‚¤ë¥¼ ì½”ë“œì— ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        tqdm.pandas(desc="í–‰ì •ë™ ë³€í™˜ ìµœì¢… ì§„í–‰ë¥ ")

        # ìˆ˜ì •ëœ í•¨ìˆ˜ë¥¼ ì ìš©í•˜ì—¬ 'í–‰ì •ë™' ì—´ ì±„ìš°ê¸°
        df['í–‰ì •ë™'] = df.progress_apply(
            lambda row: get_dong_from_coords(row['ìœ„ë„'], row['ê²½ë„'], KAKAO_API_KEY),
            axis=1
        )

        # --- 4. ê²°ê³¼ ì €ì¥ ---
        output_filename = 'final_data_with_dong_completed.csv'
        df.to_csv(output_filename, index=False, encoding='utf-8-sig')
        
        print("\n--- âœ¨ ìµœì¢… ì‘ì—… ì™„ë£Œ âœ¨ ---")
        print("ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸° (ìƒìœ„ 5ê°œ):")
        print(df[['ì´ë¦„', 'ìœ„ë„', 'ê²½ë„', 'í–‰ì •ë™']].head())
        print(f"\nëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ê²°ê³¼ê°€ '{output_filename}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

except FileNotFoundError:
    print(f"ğŸ›‘ [ì˜¤ë¥˜] íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {FILE_PATH}")
except Exception as e:
    print(f"ğŸ›‘ [ì˜¤ë¥˜] ì˜ˆìƒì¹˜ ëª»í•œ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")


final = pd.read_csv('./final_data_with_dong_completed.csv')
final['í–‰ì •ë™'].unique()




# ì„¸ë¶€í–‰ì •ë™
# --- 1. ì„¤ì • ë‹¨ê³„ ---

# ì¢Œí‘œ ë°ì´í„°ê°€ ìˆëŠ” íŒŒì¼ ê²½ë¡œë¥¼ ì§€ì •í•˜ì„¸ìš”.
FILE_PATH = 'geocoded_final_data_log.csv' 
# VWorldì—ì„œ ë°œê¸‰ë°›ì€ ê°œë°œí‚¤(API í‚¤)ë¥¼ ì…ë ¥í•˜ì„¸ìš”.
VWORLD_API_KEY = '1E64090E-B7B1-39A7-A068-2525ED16CABC'
API_URL = 'http://api.vworld.kr/req/address'

# --- 2. VWorld ë¦¬ë²„ìŠ¤ ì§€ì˜¤ì½”ë”© í•¨ìˆ˜ ---

def get_dong_from_vworld(latitude, longitude, api_key):
    """
    VWorld APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì¢Œí‘œë¥¼ ì„¸ë¶€ í–‰ì •ë™ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
    """
    if pd.isna(latitude) or pd.isna(longitude):
        return None
        
    params = {
        'service': 'address',
        'request': 'getaddress',
        'version': '2.0',
        'crs': 'epsg:4326',
        'point': f'{longitude},{latitude}', # VWorldëŠ” ê²½ë„, ìœ„ë„ ìˆœì„œ
        'format': 'json',
        'type': 'both', # ë„ë¡œëª…, ì§€ë²ˆ ì£¼ì†Œ ëª¨ë‘ ì¡°íšŒ
        'zipcode': 'true',
        'simple': 'false',
        'key': api_key
    }
    
    try:
        response = requests.get(API_URL, params=params)
        response.raise_for_status()
        data = response.json()
        
        # API ì‘ë‹µ ìƒíƒœê°€ ì •ìƒ('OK')ì¸ì§€ í™•ì¸
        if data['response']['status'] == 'OK':
            # í–‰ì •ë™ ì´ë¦„ì€ 'level4A' í•„ë“œì— ìˆìŠµë‹ˆë‹¤.
            dong_name = data['response']['result'][0]['structure']['level4A']
            return dong_name
        else:
            return None
    except Exception:
        # API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´ Noneì„ ë°˜í™˜
        return None

# --- 3. ë°ì´í„° ì²˜ë¦¬ ë° ì‹¤í–‰ ---
try:
    df = pd.read_csv('./geocoded_final_data_log.csv')
    print(f"âœ… íŒŒì¼ì„ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤: {FILE_PATH}")

    if 'YOUR_VWORLD_API_KEY' in VWORLD_API_KEY:
        print("ğŸ›‘ [ì¤‘ìš”] VWorld API í‚¤ë¥¼ ì½”ë“œì— ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        tqdm.pandas(desc="VWorld í–‰ì •ë™ ë³€í™˜ ì§„í–‰ë¥ ")

        # VWorld í•¨ìˆ˜ë¥¼ ì ìš©í•˜ì—¬ 'í–‰ì •ë™' ì—´ ì±„ìš°ê¸°
        df['í–‰ì •ë™'] = df.progress_apply(
            lambda row: get_dong_from_vworld(row['ìœ„ë„'], row['ê²½ë„'], VWORLD_API_KEY),
            axis=1
        )

        # --- 4. ìµœì¢… ê²°ê³¼ ì €ì¥ ---
        output_filename = 'final_data_completed.csv'
        df.to_csv(output_filename, index=False, encoding='utf-8-sig')
        
        print("\n--- âœ¨ ëª¨ë“  ì‘ì—… ì™„ë£Œ âœ¨ ---")
        print("ìµœì¢… ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸° (ìƒìœ„ 5ê°œ):")
        # ì´ì „ì— ìˆë˜ 'í–‰ì •ë™' ì—´ì„ ì‚­ì œí•˜ê³  ìƒˆë¡œ ì±„ìš´ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.
        if 'í–‰ì •ë™_x' in df.columns:
             df = df.drop(columns=['í–‰ì •ë™_x', 'í–‰ì •ë™_y'])
        print(df[['ì´ë¦„', 'ë„ë¡œëª…', 'í–‰ì •ë™']].head())
        print(f"\nëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ìµœì¢… ê²°ê³¼ê°€ '{output_filename}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

except FileNotFoundError:
    print(f"ğŸ›‘ [ì˜¤ë¥˜] íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {FILE_PATH}")
except Exception as e:
    print(f"ğŸ›‘ [ì˜¤ë¥˜] ì˜ˆìƒì¹˜ ëª»í•œ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

final = pd.read_csv('./final_data_completed.csv')
final.isna().sum()


# ê°€ë¡œë“± ì„¸ë¶€í–‰ì •ë™ 
# --- 1. ì„¤ì • ë‹¨ê³„ ---

# ì¢Œí‘œ ë°ì´í„°ê°€ ìˆëŠ” íŒŒì¼ ê²½ë¡œë¥¼ ì§€ì •í•˜ì„¸ìš”.
FILE_PATH = 'ê°€ë¡œë“±, ë³´ì•ˆë“±, ì•ˆì „ë²¨, CCTV.csv' 
# VWorldì—ì„œ ë°œê¸‰ë°›ì€ ê°œë°œí‚¤(API í‚¤)ë¥¼ ì…ë ¥í•˜ì„¸ìš”.
VWORLD_API_KEY = '1E64090E-B7B1-39A7-A068-2525ED16CABC'
API_URL = 'http://api.vworld.kr/req/address'

# --- 2. VWorld ë¦¬ë²„ìŠ¤ ì§€ì˜¤ì½”ë”© í•¨ìˆ˜ ---

def get_dong_from_vworld(latitude, longitude, api_key):
    """
    VWorld APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì¢Œí‘œë¥¼ ì„¸ë¶€ í–‰ì •ë™ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
    """
    if pd.isna(latitude) or pd.isna(longitude):
        return None
        
    params = {
        'service': 'address',
        'request': 'getaddress',
        'version': '2.0',
        'crs': 'epsg:4326',
        'point': f'{longitude},{latitude}', # VWorldëŠ” ê²½ë„, ìœ„ë„ ìˆœì„œ
        'format': 'json',
        'type': 'both', # ë„ë¡œëª…, ì§€ë²ˆ ì£¼ì†Œ ëª¨ë‘ ì¡°íšŒ
        'zipcode': 'true',
        'simple': 'false',
        'key': api_key
    }
    
    try:
        response = requests.get(API_URL, params=params)
        response.raise_for_status()
        data = response.json()
        
        # API ì‘ë‹µ ìƒíƒœê°€ ì •ìƒ('OK')ì¸ì§€ í™•ì¸
        if data['response']['status'] == 'OK':
            # í–‰ì •ë™ ì´ë¦„ì€ 'level4A' í•„ë“œì— ìˆìŠµë‹ˆë‹¤.
            dong_name = data['response']['result'][0]['structure']['level4A']
            return dong_name
        else:
            return None
    except Exception:
        # API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´ Noneì„ ë°˜í™˜
        return None

# --- 3. ë°ì´í„° ì²˜ë¦¬ ë° ì‹¤í–‰ ---
try:
    df1 = pd.read_csv('./ê°€ë¡œë“±, ë³´ì•ˆë“±, ì•ˆì „ë²¨, CCTV.csv', encoding='cp949')
    print(f"âœ… íŒŒì¼ì„ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤: {FILE_PATH}")

    if 'YOUR_VWORLD_API_KEY' in VWORLD_API_KEY:
        print("ğŸ›‘ [ì¤‘ìš”] VWorld API í‚¤ë¥¼ ì½”ë“œì— ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        tqdm.pandas(desc="VWorld í–‰ì •ë™ ë³€í™˜ ì§„í–‰ë¥ ")

        # VWorld í•¨ìˆ˜ë¥¼ ì ìš©í•˜ì—¬ 'í–‰ì •ë™' ì—´ ì±„ìš°ê¸°
        df1['í–‰ì •ë™'] = df1.progress_apply(
            lambda row: get_dong_from_vworld(row['ìœ„ë„'], row['ê²½ë„'], VWORLD_API_KEY),
            axis=1
        )

        # --- 4. ìµœì¢… ê²°ê³¼ ì €ì¥ ---
        output_filename = 'CCTV_data_completed.csv'
        df1.to_csv(output_filename, index=False, encoding='utf-8-sig')
        
        print("\n--- âœ¨ ëª¨ë“  ì‘ì—… ì™„ë£Œ âœ¨ ---")
        print("ìµœì¢… ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸° (ìƒìœ„ 5ê°œ):")
        # ì´ì „ì— ìˆë˜ 'í–‰ì •ë™' ì—´ì„ ì‚­ì œí•˜ê³  ìƒˆë¡œ ì±„ìš´ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.
        if 'í–‰ì •ë™_x' in df1.columns:
             df1 = df1.drop(columns=['í–‰ì •ë™_x', 'í–‰ì •ë™_y'])
        print(df1[['ì´ë¦„', 'ë„ë¡œëª…', 'í–‰ì •ë™']].head())
        print(f"\nëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ìµœì¢… ê²°ê³¼ê°€ '{output_filename}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

except FileNotFoundError:
    print(f"ğŸ›‘ [ì˜¤ë¥˜] íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {FILE_PATH}")
except Exception as e:
    print(f"ğŸ›‘ [ì˜¤ë¥˜] ì˜ˆìƒì¹˜ ëª»í•œ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

CCTV_final = pd.read_csv('./CCTV_data_completed.csv')

CCTV_final['í–‰ì •ë™'].isna().sum()
CCTV_final.loc[(CCTV_final['êµ¬ë¶„']=='ì•ˆì „ë¹„ìƒë²¨'),:].shape



# CCTV í•„í„°ë§
# --- 1. ì„¤ì • ë‹¨ê³„ ---
# ì›ë³¸ ë°ì´í„° íŒŒì¼ ê²½ë¡œë¥¼ ì§€ì •í•˜ì„¸ìš”.
FILE_PATH = 'CCTV_data_coml.csv'
# --- 2. ë°ì´í„° í•„í„°ë§ ë° ì‚­ì œ ---
try:
    # ì‚­ì œí•  ì¡°ê±´ë“¤ì„ ì •ì˜í•©ë‹ˆë‹¤.
    # ì¡°ê±´ 1: 'êµ¬ë¶„' ì¹¼ëŸ¼ì´ 'CCTV'ì¸ ê²ƒ
    condition1 = CCTV_final['êµ¬ë¶„'] == 'CCTV'
    
    # ì¡°ê±´ 2: 'ì„¤ì¹˜ëª©ì ' ì¹¼ëŸ¼ì´ ['ì°¨ëŸ‰ë°©ë²”', 'ì¬ë‚œì¬í•´', 'êµí†µë‹¨ì†'] ì¤‘ í•˜ë‚˜ì— í¬í•¨ë˜ëŠ” ê²ƒ
    purpose_to_remove = ['ì°¨ëŸ‰ë°©ë²”', 'ì¬ë‚œì¬í•´', 'êµí†µë‹¨ì†']
    condition2 = CCTV_final['ì„¤ì¹˜ëª©ì '].isin(purpose_to_remove)

    # ë‘ ì¡°ê±´ì„ ëª¨ë‘ ë§Œì¡±í•˜ëŠ” í–‰ë“¤ì„ ì°¾ìŠµë‹ˆë‹¤.
    rows_to_remove = CCTV_final[condition1 & condition2]
    print(f"  - ì‚­ì œ ëŒ€ìƒ ë°ì´í„° ê°œìˆ˜: {len(rows_to_remove)}ê°œ")

    # ìœ„ ì¡°ê±´ì— í•´ë‹¹í•˜ì§€ ì•ŠëŠ” í–‰ë“¤ë§Œ ë‚¨ê¹ë‹ˆë‹¤ (ì¦‰, ì¡°ê±´ì— ë§ëŠ” í–‰ë“¤ì„ ì‚­ì œ).
    df_filtered = CCTV_final.drop(rows_to_remove.index)
    
    print(f"  - í•„í„°ë§ í›„ ë‚¨ì€ ë°ì´í„° ê°œìˆ˜: {len(df_filtered)}ê°œ")
    
    # --- 3. ê²°ê³¼ ì €ì¥ ---
    output_filename = 'CCTV_filtered.csv'
    df_filtered.to_csv(output_filename, index=False, encoding='utf-8-sig')

    print(f"\nâœ¨ ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ê²°ê³¼ê°€ '{output_filename}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

except FileNotFoundError:
    print(f"ğŸ›‘ [ì˜¤ë¥˜] íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. '{FILE_PATH}' íŒŒì¼ì´ ìˆëŠ”ì§€, íŒŒì¼ ì´ë¦„ì„ ì •í™•íˆ ì…ë ¥í–ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
except KeyError as e:
    print(f"ğŸ›‘ [ì˜¤ë¥˜] '{e}' ì¹¼ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„° íŒŒì¼ì— 'êµ¬ë¶„'ê³¼ 'ì„¤ì¹˜ëª©ì ' ì¹¼ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
except Exception as e:
    print(f"ğŸ›‘ [ì˜¤ë¥˜] ì˜ˆìƒì¹˜ ëª»í•œ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")





# ì´ì›ƒì£¼ì†Œë¡œ ì£¼ì†Œ í• ë‹¹
from sklearn.neighbors import KNeighborsClassifier

# --- 1. ì„¤ì • ë‹¨ê³„ ---

# í–‰ì •ë™ ë°ì´í„°ê°€ ì¼ë¶€ ë¹„ì–´ìˆëŠ” íŒŒì¼ ê²½ë¡œë¥¼ ì§€ì •í•˜ì„¸ìš”.
FILE_PATH = 'CCTV_filtered.csv'
# ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì €ì¥í•  íŒŒì¼ ì´ë¦„ì„ ì§€ì •í•˜ì„¸ìš”.
OUTPUT_FILENAME = 'predicted_dong_data.csv'


# --- 2. ë°ì´í„° ì¤€ë¹„ ---

try:
    print(f"âœ… ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤: {FILE_PATH}")
    df = pd.read_csv('./CCTV_filtered.csv')
    
    # 'í–‰ì •ë™' ì—´ì´ ìˆëŠ” ë°ì´í„°(í•™ìŠµìš©)ì™€ ì—†ëŠ” ë°ì´í„°(ì˜ˆì¸¡ìš©)ë¥¼ ë¶„ë¦¬í•©ë‹ˆë‹¤.
    df_train = df.dropna(subset=['í–‰ì •ë™'])
    df_predict = df[df['í–‰ì •ë™'].isnull()]

    print(f"  - í•™ìŠµìš© ë°ì´í„° (í–‰ì •ë™ O): {len(df_train)}ê°œ")
    print(f"  - ì˜ˆì¸¡ìš© ë°ì´í„° (í–‰ì •ë™ X): {len(df_predict)}ê°œ")

    # ì˜ˆì¸¡í•  ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì¢…ë£Œ
    if df_predict.empty:
        print("\nâœ… ë¹„ì–´ìˆëŠ” í–‰ì •ë™ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì‘ì—…ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    else:
        # --- 3. ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ ---
        
        # íŠ¹ì„±(X)ì€ ìœ„ë„, ê²½ë„ / íƒ€ê²Ÿ(y)ì€ í–‰ì •ë™ìœ¼ë¡œ ì§€ì •í•©ë‹ˆë‹¤.
        X_train = df_train[['ìœ„ë„', 'ê²½ë„']]
        y_train = df_train['í–‰ì •ë™']

        print("\nâš™ï¸ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ëŠ” ì¤‘ì…ë‹ˆë‹¤... (ë°ì´í„° ì–‘ì— ë”°ë¼ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
        # KNN ëª¨ë¸ ìƒì„± (ê°€ì¥ ê°€ê¹Œìš´ 5ê°œì˜ ì´ì›ƒì„ ì°¸ê³ )
        knn = KNeighborsClassifier(n_neighbors=5, n_jobs=-1) # n_jobs=-1ì€ ëª¨ë“  CPU ì½”ì–´ë¥¼ ì‚¬ìš©í•´ ì†ë„ í–¥ìƒ

        # ëª¨ë¸ í•™ìŠµ
        knn.fit(X_train, y_train)
        print("  - ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")


        # --- 4. ë¹„ì–´ìˆëŠ” ë°ì´í„° ì˜ˆì¸¡ ---

        # ì˜ˆì¸¡í•´ì•¼ í•  ë°ì´í„°ì˜ ìœ„ë„, ê²½ë„ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        X_predict = df_predict[['ìœ„ë„', 'ê²½ë„']]
        
        print("\nğŸ”® ë¹„ì–´ìˆëŠ” í–‰ì •ë™ì„ ì˜ˆì¸¡í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤...")
        
        # í•™ìŠµëœ ëª¨ë¸ë¡œ ì˜ˆì¸¡ ì‹¤í–‰
        predicted_dongs = knn.predict(X_predict)
        print("  - ì˜ˆì¸¡ ì™„ë£Œ!")

        # --- 5. ê²°ê³¼ í•©ì¹˜ê¸° ë° ì €ì¥ ---

        # ì˜ˆì¸¡ëœ ê²°ê³¼ë¥¼ ì›ë³¸ ë°ì´í„°í”„ë ˆì„ì˜ ë¹„ì–´ìˆëŠ” ë¶€ë¶„ì— ì±„ì›Œë„£ìŠµë‹ˆë‹¤.
        df.loc[df['í–‰ì •ë™'].isnull(), 'í–‰ì •ë™'] = predicted_dongs
        
        # ê²°ê³¼ë¥¼ ìƒˆë¡œìš´ CSV íŒŒì¼ë¡œ ì €ì¥
        df.to_csv(OUTPUT_FILENAME, index=False, encoding='utf-8-sig')
        
        print(f"\nâœ¨ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ì˜ˆì¸¡ ê²°ê³¼ê°€ '{OUTPUT_FILENAME}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print("\nê²°ê³¼ ë¯¸ë¦¬ë³´ê¸° (ìƒìœ„ 5ê°œ):")
        print(df.head())


except FileNotFoundError:
    print(f"ğŸ›‘ [ì˜¤ë¥˜] íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: '{FILE_PATH}'")
except KeyError as e:
    print(f"ğŸ›‘ [ì˜¤ë¥˜] í•„ìˆ˜ ì¹¼ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}. 'ìœ„ë„', 'ê²½ë„', 'í–‰ì •ë™' ì¹¼ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
except Exception as e:
    print(f"ğŸ›‘ [ì˜¤ë¥˜] ì˜ˆìƒì¹˜ ëª»í•œ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")


# ë©”ì¸ë°ì´í„° í†µí•©
main = pd.read_excel('./ìë©´ë™ì¸êµ¬.xlsx')
main.columns

safe = pd.read_csv('./predicted_dong_data.csv')

kid_cctv = safe.loc[(safe['êµ¬ë¶„']=='CCTV')&(safe['ì„¤ì¹˜ëª©ì ']=='ì–´ë¦°ì´ë³´í˜¸'),:]
kid_cctv = kid_cctv.groupby('í–‰ì •ë™')['ìœ„ë„'].count().reset_index()
kid_cctv
main = pd.merge(main,kid_cctv,on='í–‰ì •ë™',how='left')
main['ìœ„ë„'].fillna(0, inplace=True)
main['ìœ„ë„'].sum()
main

other_cctv = safe.loc[(safe['êµ¬ë¶„']=='CCTV')&(safe['ì„¤ì¹˜ëª©ì ']!='ì–´ë¦°ì´ë³´í˜¸'),:]
other_cctv = other_cctv.groupby('í–‰ì •ë™')['ê²½ë„'].count().reset_index()
other_cctv
main = pd.merge(main,other_cctv,on='í–‰ì •ë™',how='left')
main['ê²½ë„'].fillna(0, inplace=True)
main['ê²½ë„'].sum()
main

bell = safe.loc[(safe['êµ¬ë¶„']=='ì•ˆì „ë¹„ìƒë²¨'),:]
bell = bell.groupby('í–‰ì •ë™')['ì„¤ì¹˜ëª©ì '].count().reset_index()
bell
main = pd.merge(main,bell,on='í–‰ì •ë™',how='left')
main['ì„¤ì¹˜ëª©ì '].fillna(0, inplace=True)
main['ì„¤ì¹˜ëª©ì '].sum()
main

main.to_csv('./ì •ë¦¬1.csv')
main = pd.read_excel('./ì •ë¦¬1.xlsx')
del main['Unnamed: 0.1']

light = safe.loc[(safe['êµ¬ë¶„']=='ê°€ë¡œë“±'),:]
light = light.groupby('í–‰ì •ë™')['ìœ„ë„'].count().reset_index()
light
main = pd.merge(main,light,on='í–‰ì •ë™',how='left')
main['ìœ„ë„'].fillna(0, inplace=True)
main['ìœ„ë„'].sum()
main

light2 = safe.loc[(safe['êµ¬ë¶„']=='ë³´ì•ˆë“±'),:]
light2 = light2.groupby('í–‰ì •ë™')['ê²½ë„'].count().reset_index()
light2
main = pd.merge(main,light2,on='í–‰ì •ë™',how='left')
main['ê²½ë„'].fillna(0, inplace=True)
main['ê²½ë„'].sum()
main

main.to_csv('./ì •ë¦¬2.csv')
main = pd.read_excel('./ì •ë¦¬2.xlsx')
del main['Unnamed: 0.1']
main

danger = pd.read_csv('./ìµœì¢… ìœ„í—˜ë„ì¸¡ì • ë°ì´í„°.csv')
danger
police = danger.loc[(danger['êµ¬ë¶„']=='ê²½ì°°ì„œ')|
                    (danger['êµ¬ë¶„']=='ì§€êµ¬ëŒ€')|
                    (danger['êµ¬ë¶„']=='íŒŒì¶œì†Œ')|
                    (danger['êµ¬ë¶„']=='ì¹˜ì•ˆì„¼í„°'),:]
police  = police .groupby('í–‰ì •ë™')['ì´ë¦„'].count().reset_index()
police
main = pd.merge(main,police,on='í–‰ì •ë™',how='left')
main['ì´ë¦„'].fillna(0, inplace=True)
main['ì´ë¦„'].sum()
main

uheong = danger.loc[(danger['êµ¬ë¶„']=='ìœ í¥ì£¼ì ì˜ì—…'),:]
uheong  = uheong .groupby('í–‰ì •ë™')['ë„ë¡œëª…'].count().reset_index()
uheong
main = pd.merge(main,uheong,on='í–‰ì •ë™',how='left')
main['ë„ë¡œëª…'].fillna(0, inplace=True)
main['ë„ë¡œëª…'].sum()
main

main.to_csv('./ì •ë¦¬3.csv')
main = pd.read_excel('./ì •ë¦¬3.xlsx')
del main['Unnamed: 0.1']
main

ele = danger.loc[(danger['êµ¬ë¶„']=='ì´ˆë“±í•™êµ'),:]
ele  = ele .groupby('í–‰ì •ë™')['ì´ë¦„'].count().reset_index()
ele
main = pd.merge(main,ele,on='í–‰ì •ë™',how='left')
main['ì´ë¦„'].fillna(0, inplace=True)
main['ì´ë¦„'].sum()
main

m_h = danger.loc[(danger['êµ¬ë¶„']=='ì¤‘í•™êµ')|(danger['êµ¬ë¶„']=='ê³ ë“±í•™êµ'),:]
m_h  = m_h .groupby('í–‰ì •ë™')['ë„ë¡œëª…'].count().reset_index()
m_h
main = pd.merge(main,m_h,on='í–‰ì •ë™',how='left')
main['ë„ë¡œëª…'].fillna(0, inplace=True)
main['ë„ë¡œëª…'].sum()
main

uni = danger.loc[(danger['êµ¬ë¶„']=='ëŒ€í•™êµ'),:]
uni  = uni .groupby('í–‰ì •ë™')['ì§€ë²ˆ'].count().reset_index()
uni.shape
main = pd.merge(main,uni,on='í–‰ì •ë™',how='left')
main['ì§€ë²ˆ'].fillna(0, inplace=True)
main['ì§€ë²ˆ'].sum()
main

main.to_csv('./ì •ë¦¬4.csv')

main = pd.read_excel('./ì •ë¦¬4.xlsx')
main

com = pd.read_excel('./ìƒê¶Œì •ë³´_ë™ì¶”ê°€.xlsx')
com = com.rename(columns={'í–‰ì •ë™ëª…':'í–‰ì •ë™'})
com.shape
com = com.groupby('í–‰ì •ë™')['ê²½ë„'].count().reset_index()
main = pd.merge(main,com,on='í–‰ì •ë™',how='left')
main['ê²½ë„'].fillna(0, inplace=True)
main['ê²½ë„'].sum()
main.to_csv('./ë©”ì¸.csv')

main = pd.read_excel('./main data.xlsx')
main
com = pd.read_excel('./ìƒê¶Œì •ë³´_ë™ì¶”ê°€.xlsx')
com = com.rename(columns={'í–‰ì •ë™ëª…':'í–‰ì •ë™'})
com = com.loc[(com['ìƒê¶Œì—…ì¢…ì†Œë¶„ë¥˜ëª…']=='ì…ì‹œÂ·êµê³¼í•™ì›')|
              (com['ìƒê¶Œì—…ì¢…ì†Œë¶„ë¥˜ëª…']=='ìš”ë¦¬ ì£¼ì ')|
              (com['ìƒê¶Œì—…ì¢…ì†Œë¶„ë¥˜ëª…']=='ì¼ë°˜ ìœ í¥ ì£¼ì '),:]
com = com.groupby(['í–‰ì •ë™','ìƒê¶Œì—…ì¢…ì†Œë¶„ë¥˜ëª…'])['ìƒí˜¸ëª…'].count().reset_index()
com = com.pivot_table(index='í–‰ì •ë™',
                      columns='ìƒê¶Œì—…ì¢…ì†Œë¶„ë¥˜ëª…',
                      values='ìƒí˜¸ëª…').fillna(0)
main = pd.merge(main,com,on='í–‰ì •ë™',how='left')
main
main.to_excel('./Main data.xlsx')











main = pd.read_csv('./df1_main_data_detailed.csv')
main
del main['col_0']
main

safe = pd.read_csv('./ìµœì¢… ì•ˆì „ì ìˆ˜ ë°ì´í„°.csv')
cctv = safe.loc[(safe['êµ¬ë¶„']=='CCTV'),:]
cctv['ì„¤ì¹˜ëª©ì '].unique()
sang_cctv = cctv.loc[(cctv['ì„¤ì¹˜ëª©ì ']=='ìƒí™œë°©ë²”'),:]
sang = sang_cctv.groupby('í–‰ì •ë™')['ê°œìˆ˜'].sum().reset_index()
main = pd.merge(main,sang,on='í–‰ì •ë™',how='left')
main['ê°œìˆ˜'].fillna(0,inplace=True) # ê°œìˆ˜_x

si = cctv.loc[(cctv['ì„¤ì¹˜ëª©ì ']=='ì‹œì„¤ë¬¼ê´€ë¦¬'),:]
si = si.groupby('í–‰ì •ë™')['ê°œìˆ˜'].sum().reset_index()
main = pd.merge(main,si,on='í–‰ì •ë™',how='left')
main['ê°œìˆ˜'].fillna(0,inplace=True) # ê°œìˆ˜

gi = cctv.loc[(cctv['ì„¤ì¹˜ëª©ì ']=='ê¸°íƒ€'),:]
gi = gi.groupby('í–‰ì •ë™')['ê°œìˆ˜'].sum().reset_index()
main = pd.merge(main,gi,on='í–‰ì •ë™',how='left', suffixes=('_total', '_gi'))
main['ê°œìˆ˜'].fillna(0,inplace=True) 

ss = cctv.loc[(cctv['ì„¤ì¹˜ëª©ì ']=='ì“°ë ˆê¸°ë‹¨ì†'),:]
ss = ss.groupby('í–‰ì •ë™')['ê°œìˆ˜'].sum().reset_index()
main = pd.merge(main,ss,on='í–‰ì •ë™',how='left', suffixes=('_si', '_ss'))
main['ê°œìˆ˜_ss'].fillna(0,inplace=True) 


other = cctv.loc[(cctv['ì„¤ì¹˜ëª©ì ']!='ì–´ë¦°ì´ë³´í˜¸'),:]
other = other.groupby('í–‰ì •ë™')['ê°œìˆ˜'].sum().reset_index()
main = pd.merge(main,other,on='í–‰ì •ë™',how='left')
main['ê°œìˆ˜'].fillna(0,inplace=True) # ê°œìˆ˜_total


main.to_csv('./df1_main_data.csv')

main


# ë¶„ê¸°ë³„ ë²”ì£„ìˆ˜/ë²”ì£„ìœ¨ ì¦ê° ì‹œê°í™”
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from io import StringIO
import platform

# 1. ë°ì´í„° ì¤€ë¹„
# './ë²”ì£„ìœ¨ ì¦ê°.xlsx' íŒŒì¼ì—ì„œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
# íŒŒì¼ ê²½ë¡œê°€ ì½”ë“œ ì‹¤í–‰ ìœ„ì¹˜ì™€ ë§ëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.
try:
    # ì‚¬ìš©ìê°€ ìš”ì²­í•œ ëŒ€ë¡œ Excel íŒŒì¼ì—ì„œ ë°ì´í„°ë¥¼ ì½ì–´ì˜µë‹ˆë‹¤.
    df = pd.read_excel('./ë²”ì£„ìœ¨ ì¦ê°.xlsx')
except FileNotFoundError:
    print("ì˜¤ë¥˜: './ë²”ì£„ìœ¨ ì¦ê°.xlsx' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print("ì½”ë“œì™€ ê°™ì€ í´ë”ì— íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
    # íŒŒì¼ì´ ì—†ì„ ê²½ìš°, ë¹ˆ ë°ì´í„°í”„ë ˆì„ì„ ìƒì„±í•˜ì—¬ ì˜¤ë¥˜ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.
    df = pd.DataFrame()

# ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆì„ ê²½ìš°ì—ë§Œ í›„ì† ì½”ë“œë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
if not df.empty:
    # 2. ë°ì´í„° ì „ì²˜ë¦¬
    # 'Unnamed: 0' ì»¬ëŸ¼ì„ ì¸ë±ìŠ¤ë¡œ ì„¤ì •í•˜ê³ , ë¶ˆí•„ìš”í•œ ì²« ë²ˆì§¸ ì¸ë±ìŠ¤ ì»¬ëŸ¼ì€ ì œê±°í•©ë‹ˆë‹¤.
    # Excel íŒŒì¼ì˜ ì²« ë²ˆì§¸ ì—´ ì´ë¦„ì´ ë‹¤ë¥¼ ê²½ìš°, 'Unnamed: 0' ë¶€ë¶„ì„ ì‹¤ì œ ì—´ ì´ë¦„ìœ¼ë¡œ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤.
    df = df.set_index('Unnamed: 0').iloc[:, 1:]

    # í–‰ê³¼ ì—´ì„ ë°”ê¿”ì„œ(Transpose) ë¶„ê¸°ë³„ ë°ì´í„°ë¥¼ ë‹¤ë£¨ê¸° ì‰½ê²Œ ë§Œë“­ë‹ˆë‹¤.
    df_t = df.transpose()

    # 3. ì‹œê°í™” (ë©”ì‹œì§€ ê°•ì¡° ë²„ì „)
    # í•œê¸€ í°íŠ¸ ì„¤ì • (Windows, Mac, Linux í™˜ê²½ì— ë§ê²Œ ìë™ ì„¤ì •)
    if platform.system() == 'Windows':
        plt.rc('font', family='Malgun Gothic')
    elif platform.system() == 'Darwin': # Mac
        plt.rc('font', family='AppleGothic')
    else: # Linux
        plt.rc('font', family='NanumGothic')

    # ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ ê¹¨ì§ ë°©ì§€
    plt.rcParams['axes.unicode_minus'] = False

    # 2ê°œì˜ ê·¸ë˜í”„ë¥¼ ë‹´ì„ Figureì™€ Axes ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    fig, axes = plt.subplots(2, 1, figsize=(12, 14))
    fig.suptitle('ë¶„ê¸°ë³„ ë²”ì£„ ë™í–¥ ë¶„ì„', fontsize=22, y=1.03)

    # --- ê·¸ë˜í”„ 1: ì „ë…„ ë™ë¶„ê¸° ëŒ€ë¹„ ë²”ì£„ ë°œìƒ ì¦ê°ë¥  ---
    colors = ['crimson' if x > 0 else 'royalblue' for x in df_t['ì „ë…„ë™ë¶„ê¸° ëŒ€ë¹„ ë°œìƒê±´ìˆ˜ ì¦ê°ë¥ (%)']]
    sns.barplot(x=df_t.index, y=df_t['ì „ë…„ë™ë¶„ê¸° ëŒ€ë¹„ ë°œìƒê±´ìˆ˜ ì¦ê°ë¥ (%)'], ax=axes[0], palette=colors)
    axes[0].set_title('ì „ë…„ ë™ë¶„ê¸° ëŒ€ë¹„ ë²”ì£„ ë°œìƒë¥ ì€ ê³„ì† ì¦ê°€ ì¶”ì„¸', fontsize=16, pad=20)
    axes[0].set_ylabel('ì¦ê°ë¥  (%)')
    axes[0].axhline(0, color='grey', linewidth=0.8) # 0% ê¸°ì¤€ì„  ì¶”ê°€
    axes[0].grid(axis='y', linestyle='--', alpha=0.6)

    # ë§‰ëŒ€ ìœ„ì— ê°’ í‘œì‹œ
    for p in axes[0].patches:
        axes[0].annotate(f'{p.get_height()}%', (p.get_x() + p.get_width() / 2., p.get_height()),
                         ha='center', va='center', xytext=(0, 10), textcoords='offset points', fontsize=11)

    axes[0].annotate('24ë…„ 3ë¶„ê¸°ë¥¼ ì œì™¸í•˜ê³ \në§¤ ë¶„ê¸° ì „ë…„ ëŒ€ë¹„ ë²”ì£„ ì¦ê°€', 
                     xy=(0.95, 0.95), xycoords='axes fraction',
                     ha='right', va='top',
                     bbox=dict(boxstyle='round,pad=0.5', fc='wheat', alpha=0.5),
                     fontsize=13)

    # --- ê·¸ë˜í”„ 2: ê²€ê±°ìœ¨ í•˜ë½ ì¶”ì„¸ ê°•ì¡° ---
    sns.lineplot(data=df_t['ë°œìƒê±´ìˆ˜ëŒ€ë¹„ ê²€ê±°ê±´ìˆ˜(%)'], ax=axes[1], marker='o', color='darkorange', linewidth=2.5)
    axes[1].set_title('ì¦ê°€í•˜ëŠ” ë²”ì£„ìœ¨ê³¼ ë‹¬ë¦¬ ê²€ê±°ìœ¨ì€ í•˜ë½ì„¸', fontsize=16, pad=20)
    axes[1].set_ylabel('ê²€ê±°ìœ¨ (%)')
    axes[1].grid(True, linestyle='--', alpha=0.6)

    # ìµœì €ì (ê°€ì¥ ë‚®ì€ ê²€ê±°ìœ¨)ì— í…ìŠ¤íŠ¸ ê°•ì¡°
    min_period = df_t['ë°œìƒê±´ìˆ˜ëŒ€ë¹„ ê²€ê±°ê±´ìˆ˜(%)'].idxmin()
    min_value = df_t['ë°œìƒê±´ìˆ˜ëŒ€ë¹„ ê²€ê±°ê±´ìˆ˜(%)'].min()
    axes[1].text(min_period, min_value, f'  {min_value}% (ìµœì €)', 
                 color='blue', verticalalignment='top', fontsize=12, fontweight='bold')
    
    # í•˜ë½ ì¶”ì„¸ ê°•ì¡°ë¥¼ ìœ„í•œ í™”ì‚´í‘œì™€ í…ìŠ¤íŠ¸ ì¶”ê°€
    axes[1].annotate('ëŒ€ì‘ íš¨ìœ¨ì„± ì €í•˜', 
                     xy=(len(df_t)-2, df_t['ë°œìƒê±´ìˆ˜ëŒ€ë¹„ ê²€ê±°ê±´ìˆ˜(%)'].iloc[-3]), 
                     xytext=(len(df_t)-4, df_t['ë°œìƒê±´ìˆ˜ëŒ€ë¹„ ê²€ê±°ê±´ìˆ˜(%)'].iloc[-3] - 10),
                     arrowprops=dict(facecolor='royalblue', shrink=0.05, alpha=0.7, connectionstyle="arc3,rad=0.2"),
                     fontsize=14, color='royalblue', fontweight='bold')


    # ì „ì²´ ë ˆì´ì•„ì›ƒì„ ê¹”ë”í•˜ê²Œ ì¡°ì •í•©ë‹ˆë‹¤.
    plt.tight_layout(rect=[0, 0, 1, 0.97])

    # ê·¸ë˜í”„ë¥¼ í™”ë©´ì— ë³´ì—¬ì¤ë‹ˆë‹¤.
    plt.show()







# ìŠ¤ì¼€ì¼ë§
df = pd.read_csv('./df1_main_data - ìœ„í—˜ë„ ê³„ì‚°ìš©.csv')
import pandas as pd
from sklearn.preprocessing import RobustScaler, MinMaxScaler
from sklearn.pipeline import Pipeline

# ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ì„ íƒ
numeric_cols = ['ì¹˜ì•ˆê¸°ê´€','ìœ í¥ì—…ì†Œ ìˆ˜','ì´ˆë“±í•™êµ ìˆ˜',
                'ì¤‘,ê³ ë“±í•™êµ ìˆ˜','ì–´ë¦°ì´ìš© CCTV ìˆ˜','ì•ˆì „ë¹„ìƒë²¨ ìˆ˜',
                'ìš”ë¦¬ ì£¼ì ','ì…ì‹œÂ·êµê³¼í•™ì›','ê¸°íƒ€ CCTV ìˆ˜',
                'ì‹œì„¤ë¬¼ CCTV ìˆ˜', 'ì“°ë ˆê¸°ë‹¨ì† CCTV ìˆ˜']

# RobustScaler + MinMaxScaler íŒŒì´í”„ë¼ì¸
scaler = Pipeline([
    ('robust', RobustScaler()), 
    ('minmax', MinMaxScaler(feature_range=(0, 10)))
])
scaled_values = scaler.fit_transform(df[numeric_cols])
# ìƒˆë¡œìš´ ë°ì´í„°í”„ë ˆì„ ìƒì„±
df_scaled = pd.DataFrame(scaled_values, columns=numeric_cols, index=df.index)
# ë²”ì£¼í˜• ì—´ ë¶™ì´ê¸°
df_scaled = pd.concat([df.drop(columns=numeric_cols), df_scaled], axis=1)
print(df_scaled.head())
df_scaled.to_csv('./1.csv')



total = pd.read_csv('./ë¹¨ê°„ìƒ‰,ë…¸ë€ìƒ‰.csv')
total.drop(0,axis=0,inplace=True)
total

